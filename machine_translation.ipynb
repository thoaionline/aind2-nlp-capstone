{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Machine Translation Project\n",
    "In this notebook, sections that end with **'(IMPLEMENTATION)'** in the header indicate that the following blocks of code will require additional functionality which you must provide. Please be sure to read the instructions carefully!\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you will build a deep neural network that functions as part of an end-to-end machine translation pipeline. Your completed pipeline will accept English text as input and return the French translation.\n",
    "\n",
    "- **Preprocess** - You'll convert text to sequence of integers.\n",
    "- **Models** Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations. After learning about the basic types of neural networks that are often used for machine translation, you will engage in your own investigations, to design your own model!\n",
    "- **Prediction** Run the model on English text.\n",
    "\n",
    "## Dataset\n",
    "We begin by investigating the dataset that will be used to train and evaluate your pipeline.  The most common datasets used for machine translation are from [WMT](http://www.statmt.org/).  However, that will take a long time to train a neural network on.  We'll be using a dataset we created for this project that contains a small vocabulary.  You'll be able to train your model in a reasonable time with this dataset.\n",
    "### Load Data\n",
    "The data is located in `data/small_vocab_en` and `data/small_vocab_fr`. The `small_vocab_en` file contains English sentences with their French translations in the `small_vocab_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "# Load English data\n",
    "english_sentences = helper.load_data('data/small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = helper.load_data('data/small_vocab_fr')\n",
    "\n",
    "print('Dataset Loaded')\n",
    "\n",
    "print((english_sentences[1]))\n",
    "print((french_sentences[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "Each line in `small_vocab_en` contains an English sentence with the respective translation in each line of `small_vocab_fr`.  View the first two lines from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "small_vocab_fr Line 2:  les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre .\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(2):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the sentences, you can see they have been preprocessed already.  The puncuations have been delimited using spaces. All the text have been converted to lowercase.  This should save you some time, but the text requires more preprocessing.\n",
    "### Vocabulary\n",
    "The complexity of the problem is determined by the complexity of the vocabulary.  A more complex vocabulary is a more complex problem.  Let's look at the complexity of the dataset we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, _Alice's Adventures in Wonderland_ contains 2,766 unique words of a total of 15,500 words.\n",
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Tokenize the words into ids\n",
    "2. Add padding to make all the sequences the same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize (IMPLEMENTATION)\n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "Running the cell will run `tokenize` on sample data and show output for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my': 4, 'is': 5, 'a': 3, 'dog': 16, 'this': 8, 'by': 9, 'fox': 17, 'won': 11, 'lazy': 6, 'jumps': 18, 'over': 14, 'sentence': 15, 'study': 12, 'brown': 7, 'lexicography': 10, 'short': 13, 'quick': 1, 'the': 2, 'jove': 19, 'of': 20, 'prize': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [2, 1, 7, 17, 18, 14, 2, 6, 16]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [9, 19, 4, 1, 12, 20, 10, 11, 3, 21]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [8, 5, 3, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "import project_tests as tests\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "    return tokenized_sentences, tokenizer\n",
    "\n",
    "tests.test_tokenize(tokenize)\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding (IMPLEMENTATION)\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length.  Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the **end** of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [ 2  1  7 17 18 14  2  6 16]\n",
      "  Output: [ 2  1  7 17 18 14  2  6 16  0]\n",
      "Sequence 2 in x\n",
      "  Input:  [ 9 19  4  1 12 20 10 11  3 21]\n",
      "  Output: [ 9 19  4  1 12 20 10 11  3 21]\n",
      "Sequence 3 in x\n",
      "  Input:  [ 8  5  3 13 15]\n",
      "  Output: [ 8  5  3 13 15  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    return pad_sequences(x,padding='post',maxlen=length)\n",
    "\n",
    "tests.test_pad(pad)\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Pipeline\n",
    "Your focus for this project is to build neural network architecture, so we won't ask you to create a preprocess pipeline.  Instead, we've provided you with the implementation of the `preprocess` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    #if preprocess_x.shape[1] > preprocess_y.shape[1]:\n",
    "    #    preprocess_y = pad(preprocess_y, preprocess_x.shape[1])\n",
    "    #elif preprocess_x.shape[1] < preprocess_y.shape[1]:\n",
    "    #    preprocess_x = pad(preprocess_x, preprocess_y.shape[1])\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    \n",
    "    #total_tokens = len(y_tk.word_index) + 1\n",
    "    #preprocess_y = np.array([to_categorical(preprocess_y[i],total_tokens) for i in range(len(preprocess_y))])\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 21 20  1  9 62  4 43  7  3  1  9 51  2 45]\n",
      "[[ 4]\n",
      " [32]\n",
      " [31]\n",
      " [ 1]\n",
      " [12]\n",
      " [19]\n",
      " [ 2]\n",
      " [49]\n",
      " [ 6]\n",
      " [ 3]\n",
      " [95]\n",
      " [69]\n",
      " [ 2]\n",
      " [51]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "print(preproc_english_sentences[1])\n",
    "print(preproc_french_sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this section, you will experiment with various neural network architectures.\n",
    "You will begin by training four relatively simple architectures.\n",
    "- Model 1 is a simple RNN\n",
    "- Model 2 is a RNN with Embedding\n",
    "- Model 3 is a Bidirectional RNN\n",
    "- Model 4 is an optional Encoder-Decoder RNN\n",
    "\n",
    "After experimenting with the four simple architectures, you will construct a deeper architecture that is designed to outperform all four models.\n",
    "### Ids Back to Text\n",
    "The neural network will be translating the input to words ids, which isn't the final form we want.  We want the French translation.  The function `logits_to_text` will bridge the gab between the logits from the neural network to the French translation.  You'll be using this function to better understand the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: RNN (IMPLEMENTATION)\n",
    "![RNN](images/rnn.png)\n",
    "A basic RNN model is a good baseline for sequence data.  In this model, you'll build a RNN that translates English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137861, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "print(tmp_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 21, 21)            1932      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 21, 346)           7612      \n",
      "=================================================================\n",
      "Total params: 9,544.0\n",
      "Trainable params: 9,544\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU, Input, Dense, TimeDistributed, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(output_sequence_length, input_shape=input_shape[1:], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tests.test_simple_model(simple_model)\n",
    "\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index) + 1, # Add a code for padding\n",
    "    len(french_tokenizer.word_index) + 1,\n",
    "    learning_rate=0.005 # Lowered learning rate for better fit\n",
    ")\n",
    "\n",
    "print(simple_rnn_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137861, 21, 1)\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 3s - loss: 11.5894 - acc: 0.0117 - val_loss: 8.0406 - val_acc: 0.1316\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 2s - loss: 7.7235 - acc: 0.1976 - val_loss: 7.1691 - val_acc: 0.3215\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 2s - loss: 7.0291 - acc: 0.3506 - val_loss: 6.8691 - val_acc: 0.4167\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.7895 - acc: 0.4273 - val_loss: 6.7963 - val_acc: 0.4422\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.7667 - acc: 0.4466 - val_loss: 6.7393 - val_acc: 0.4207\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.7421 - acc: 0.4148 - val_loss: 6.6994 - val_acc: 0.4082\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.6890 - acc: 0.4070 - val_loss: 6.6715 - val_acc: 0.4079\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.6635 - acc: 0.4091 - val_loss: 6.6193 - val_acc: 0.4114\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 2s - loss: 6.6179 - acc: 0.4102 - val_loss: 6.5992 - val_acc: 0.4115\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 6s - loss: 6.5852 - acc: 0.4128 - val_loss: 6.5572 - val_acc: 0.4251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9dffd6e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preproc_french_sentences.shape)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "simple_rnn_model.fit(\n",
    "    tmp_x, \n",
    "    preproc_french_sentences, \n",
    "    batch_size=36762, epochs=10, validation_split=0.2#,\n",
    "    #callbacks = [EarlyStopping(monitor='val_acc', patience=3, mode='max')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 346)\n",
      "ENGLISH:  that cat was my most loved animal .\n",
      "FRENCH:  elle est est est est est est <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "[17]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print prediction(s)\n",
    "\n",
    "def preview_sentence(sentence_index,input_x,model):\n",
    "    print(model.predict(input_x[sentence_index:sentence_index+1]).shape)\n",
    "    print('ENGLISH: ',english_sentences[sentence_index])\n",
    "    print('FRENCH: ',\n",
    "        logits_to_text(\n",
    "            model.predict(input_x[sentence_index:sentence_index+1])[0],\n",
    "            french_tokenizer\n",
    "        )\n",
    "    )\n",
    "    pass\n",
    "\n",
    "preview_sentence(13,tmp_x,simple_rnn_model)\n",
    "\n",
    "print(tmp_x[0][0])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Embedding (IMPLEMENTATION)\n",
    "![RNN](images/embedding.png)\n",
    "You've turned the words into ids, but there's a better representation of a word.  This is called word embeddings.  An embedding is a vector representation of the word that is close to similar words in n-dimensional space, where the n represents the size of the embedding vectors.\n",
    "\n",
    "In this model, you'll create a RNN model using embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "max_length = max(preproc_english_sentences.shape[1],preproc_french_sentences.shape[1])\n",
    "padded_x = pad(preproc_english_sentences, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 344)           68456     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 21, 21)            30744     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 21, 344)           7568      \n",
      "=================================================================\n",
      "Total params: 106,768.0\n",
      "Trainable params: 106,768\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 21, 346)           69200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 21, 21)            30912     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 21, 346)           7612      \n",
      "=================================================================\n",
      "Total params: 107,724.0\n",
      "Trainable params: 107,724\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(\n",
    "        input_length = input_shape[1],\n",
    "        input_dim=english_vocab_size,\n",
    "        output_dim = french_vocab_size\n",
    "    ))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        output_sequence_length,\n",
    "        input_shape = input_shape[1:],\n",
    "        return_sequences = True           \n",
    "    ))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tests.test_embed_model(embed_model)\n",
    "\n",
    "embed_rnn = embed_model(\n",
    "    padded_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index) + 1,\n",
    "    len(french_tokenizer.word_index) + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 4s - loss: 9.0230 - acc: 0.0050 - val_loss: 5.2526 - val_acc: 0.4328\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 3s - loss: 4.9327 - acc: 0.4515 - val_loss: 4.2269 - val_acc: 0.4879\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 3s - loss: 4.0991 - acc: 0.4957 - val_loss: 3.7883 - val_acc: 0.5202\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 3s - loss: 3.6922 - acc: 0.5221 - val_loss: 3.4377 - val_acc: 0.5291\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 3s - loss: 3.3508 - acc: 0.5281 - val_loss: 3.1300 - val_acc: 0.5378\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 3s - loss: 3.0652 - acc: 0.5376 - val_loss: 2.8864 - val_acc: 0.5369\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 3s - loss: 2.8409 - acc: 0.5359 - val_loss: 2.7207 - val_acc: 0.5398\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 3s - loss: 2.6641 - acc: 0.5377 - val_loss: 2.5289 - val_acc: 0.5269\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 3s - loss: 2.4893 - acc: 0.5239 - val_loss: 2.3976 - val_acc: 0.5170\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 3s - loss: 2.3798 - acc: 0.5165 - val_loss: 2.3469 - val_acc: 0.5123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9ef7f2d68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train the neural network\n",
    "embed_rnn.fit(\n",
    "    padded_x,preproc_french_sentences,\n",
    "    batch_size=36762, epochs=10, validation_split=0.2#,\n",
    "    #callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 346)\n",
      "ENGLISH:  his favorite fruit is the orange , but my favorite is the grape .\n",
      "FRENCH:  gã©nã©ralement <PAD> <PAD> est est est <PAD> <PAD> <PAD> est est <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print prediction(s)\n",
    "preview_sentence(5,padded_x,embed_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional RNNs (IMPLEMENTATION)\n",
    "![RNN](images/bidirectional.png)\n",
    "One restriction of a RNN is that it can't see the future input, only the past.  This is where bidirectional recurrent neural networks come in.  They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 21, 21)            3864      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 21, 344)           7568      \n",
      "=================================================================\n",
      "Total params: 11,432.0\n",
      "Trainable params: 11,432\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                output_sequence_length,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            input_shape=input_shape[1:],\n",
    "            merge_mode='sum'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "tests.test_bd_model(bd_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 21, 21)            3864      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 21, 346)           7612      \n",
      "=================================================================\n",
      "Total params: 11,476.0\n",
      "Trainable params: 11,476\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bd_rnn = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index) + 1,\n",
    "    len(french_tokenizer.word_index) + 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/20\n",
      "110288/110288 [==============================] - 5s - loss: 12.4813 - acc: 1.4076e-04 - val_loss: 9.3910 - val_acc: 0.0015\n",
      "Epoch 2/20\n",
      "110288/110288 [==============================] - 3s - loss: 8.9461 - acc: 0.0200 - val_loss: 7.9521 - val_acc: 0.0751\n",
      "Epoch 3/20\n",
      "110288/110288 [==============================] - 3s - loss: 7.8226 - acc: 0.0858 - val_loss: 7.4578 - val_acc: 0.1257\n",
      "Epoch 4/20\n",
      "110288/110288 [==============================] - 3s - loss: 7.3457 - acc: 0.1358 - val_loss: 6.8903 - val_acc: 0.1647\n",
      "Epoch 5/20\n",
      "110288/110288 [==============================] - 3s - loss: 6.8062 - acc: 0.1781 - val_loss: 6.4463 - val_acc: 0.2140\n",
      "Epoch 6/20\n",
      "110288/110288 [==============================] - 3s - loss: 6.3722 - acc: 0.2258 - val_loss: 6.1509 - val_acc: 0.2510\n",
      "Epoch 7/20\n",
      "110288/110288 [==============================] - 3s - loss: 6.0956 - acc: 0.2586 - val_loss: 5.9021 - val_acc: 0.2833\n",
      "Epoch 8/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.8572 - acc: 0.2938 - val_loss: 5.6975 - val_acc: 0.3201\n",
      "Epoch 9/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.6617 - acc: 0.3260 - val_loss: 5.5373 - val_acc: 0.3608\n",
      "Epoch 10/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.5081 - acc: 0.3667 - val_loss: 5.4037 - val_acc: 0.3890\n",
      "Epoch 11/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.3813 - acc: 0.4017 - val_loss: 5.2904 - val_acc: 0.4228\n",
      "Epoch 12/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.2730 - acc: 0.4297 - val_loss: 5.1987 - val_acc: 0.4537\n",
      "Epoch 13/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.1863 - acc: 0.4561 - val_loss: 5.1171 - val_acc: 0.4642\n",
      "Epoch 14/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.1074 - acc: 0.4641 - val_loss: 5.0535 - val_acc: 0.4683\n",
      "Epoch 15/20\n",
      "110288/110288 [==============================] - 3s - loss: 5.0445 - acc: 0.4672 - val_loss: 4.9881 - val_acc: 0.4677\n",
      "Epoch 16/20\n",
      "110288/110288 [==============================] - 3s - loss: 4.9762 - acc: 0.4662 - val_loss: 4.9322 - val_acc: 0.4638\n",
      "Epoch 17/20\n",
      "110288/110288 [==============================] - 3s - loss: 4.9276 - acc: 0.4600 - val_loss: 4.8963 - val_acc: 0.4564\n",
      "Epoch 18/20\n",
      "110288/110288 [==============================] - 3s - loss: 4.8864 - acc: 0.4541 - val_loss: 4.8422 - val_acc: 0.4530\n",
      "Epoch 19/20\n",
      "110288/110288 [==============================] - 3s - loss: 4.8438 - acc: 0.4515 - val_loss: 4.8124 - val_acc: 0.4525\n",
      "Epoch 20/20\n",
      "110288/110288 [==============================] - 3s - loss: 4.8139 - acc: 0.4504 - val_loss: 4.7824 - val_acc: 0.4531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9f55b3d68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train and Print prediction(s)\n",
    "bd_rnn.fit(tmp_x, preproc_french_sentences,\n",
    "    batch_size=36762, epochs=20, validation_split=0.2#,\n",
    "    #callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 346)\n",
      "ENGLISH:  the united states is sometimes mild during june , and it is cold in september .\n",
      "FRENCH:  est est est est est est est est est est <PAD> il <PAD> il <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "preview_sentence(3,tmp_x,bd_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Encoder-Decoder (OPTIONAL)\n",
    "Time to look at encoder-decoder models.  This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence.  The decoder takes this matrix as input and predicts the translation as output.\n",
    "\n",
    "Create an encoder-decoder model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 21, 256)           393984    \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 21, 344)           88408     \n",
      "=================================================================\n",
      "Total params: 680,536.0\n",
      "Trainable params: 680,536.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import RepeatVector\n",
    "\n",
    "\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # OPTIONAL: Implement\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(GRU(256,input_shape=input_shape[1:]))\n",
    "\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "\n",
    "    model.add(GRU(256,input_shape=input_shape[1:], return_sequences = True))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(0.003),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "tests.test_encdec_model(encdec_model)\n",
    "\n",
    "\n",
    "# OPTIONAL: Train and Print prediction(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Custom (IMPLEMENTATION)\n",
    "Use everything you learned from the previous models to create a model that incorporates embedding and a bidirectional rnn into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Loaded\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 346)           69200     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 512)           2638848   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 21, 346)           1783284   \n",
      "=================================================================\n",
      "Total params: 4,491,332.0\n",
      "Trainable params: 4,491,332\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import project_tests as tests\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(\n",
    "        input_length = input_shape[1],\n",
    "        input_dim=english_vocab_size,\n",
    "        output_dim = french_vocab_size\n",
    "    ))\n",
    "    \n",
    "    # TODO: Implement encoder\n",
    "    #model.add(GRU(input_shape[1]))\n",
    "    #model.add(RepeatVector(output_sequence_length))\n",
    "\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                512,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            merge_mode='sum'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                french_vocab_size,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            merge_mode='sum'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    #model.add(TimeDistributed(Dense()))\n",
    "\n",
    "    model.compile(\n",
    "        loss=sparse_categorical_crossentropy,\n",
    "        optimizer=Adam(0.003),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "#tests.test_model_final(model_final) # Test will fail without encoder-decoder\n",
    "\n",
    "print('Final Model Loaded')\n",
    "\n",
    "final_rnn = model_final(\n",
    "    padded_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index) + 1,\n",
    "    len(french_tokenizer.word_index) + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/2\n",
      "110288/110288 [==============================] - 68s - loss: 3.2855 - acc: 0.4768 - val_loss: 1.5056 - val_acc: 0.6425\n",
      "Epoch 2/2\n",
      "110288/110288 [==============================] - 66s - loss: 1.4696 - acc: 0.6242 - val_loss: 1.1878 - val_acc: 0.6602\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJBRsEvIhJkFPwiIkFGwS8iEmT+F2Oi6XsizGQxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f9fb020c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a test run, full training below\n",
    "import keras.callbacks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# CODE FROM https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        # self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        # plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend(prop={'size': 6})\n",
    "        plt.show();\n",
    "\n",
    "\n",
    "history = final_rnn.fit(\n",
    "    padded_x, preproc_french_sentences,    \n",
    "    batch_size=4000, epochs=2, validation_split=0.2,\n",
    "    callbacks=[PlotLosses()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 346)\n",
      "ENGLISH:  the united states is sometimes mild during june , and it is cold in september .\n",
      "FRENCH:  les ã©tats unis est parfois doux en juin et il est est en septembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "preview_sentence(3,padded_x,final_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction (IMPLEMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 21, 346)           69200     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 21, 512)           2638848   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 21, 346)           1783284   \n",
      "=================================================================\n",
      "Total params: 4,491,332.0\n",
      "Trainable params: 4,491,332\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "136000/137861 [============================>.] - ETA: 1s - loss: 4.7023 - acc: 0.3481Epoch 00000: acc improved from -inf to 0.34998, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 89s - loss: 4.6674 - acc: 0.3500    \n",
      "Epoch 2/10000\n",
      "136000/137861 [============================>.] - ETA: 1s - loss: 3.1964 - acc: 0.4284Epoch 00001: acc improved from 0.34998 to 0.42697, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 77s - loss: 3.1954 - acc: 0.4270    \n",
      "Epoch 3/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 2.2952 - acc: 0.4536Epoch 00002: acc improved from 0.42697 to 0.45473, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 68s - loss: 2.2892 - acc: 0.4547    \n",
      "Epoch 4/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.9442 - acc: 0.4711Epoch 00003: acc improved from 0.45473 to 0.47238, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 1.9408 - acc: 0.4724    \n",
      "Epoch 5/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.5134 - acc: 0.5959Epoch 00004: acc improved from 0.47238 to 0.59621, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 70s - loss: 1.5123 - acc: 0.5962    \n",
      "Epoch 6/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3505 - acc: 0.6276Epoch 00005: acc improved from 0.59621 to 0.62658, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 68s - loss: 1.3503 - acc: 0.6266    \n",
      "Epoch 7/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.4986 - acc: 0.4950Epoch 00006: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 1.4989 - acc: 0.4950    \n",
      "Epoch 8/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3238 - acc: 0.5444Epoch 00007: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 1.3218 - acc: 0.5449    \n",
      "Epoch 9/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.5993 - acc: 0.4664Epoch 00008: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 1.6006 - acc: 0.4659    \n",
      "Epoch 10/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3738 - acc: 0.5227Epoch 00009: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.3718 - acc: 0.5233    \n",
      "Epoch 11/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3475 - acc: 0.5478Epoch 00010: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 1.3462 - acc: 0.5482    \n",
      "Epoch 12/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.2374 - acc: 0.6101Epoch 00011: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 1.2360 - acc: 0.6108    \n",
      "Epoch 13/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0941 - acc: 0.6643Epoch 00012: acc improved from 0.62658 to 0.66433, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 1.0948 - acc: 0.6643    \n",
      "Epoch 14/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0690 - acc: 0.6715Epoch 00013: acc improved from 0.66433 to 0.67083, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 1.0692 - acc: 0.6708    \n",
      "Epoch 15/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.1658 - acc: 0.5930Epoch 00014: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.1638 - acc: 0.5936    \n",
      "Epoch 16/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0196 - acc: 0.6523Epoch 00015: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0204 - acc: 0.6517    \n",
      "Epoch 17/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.4235 - acc: 0.6093Epoch 00016: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.4194 - acc: 0.6100    \n",
      "Epoch 18/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.1509 - acc: 0.6657Epoch 00017: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 1.1507 - acc: 0.6656    \n",
      "Epoch 19/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3348 - acc: 0.6123Epoch 00018: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 1.3339 - acc: 0.6121    \n",
      "Epoch 20/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0893 - acc: 0.6667Epoch 00019: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0878 - acc: 0.6670    \n",
      "Epoch 21/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9852 - acc: 0.6899Epoch 00020: acc improved from 0.67083 to 0.68995, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.9848 - acc: 0.6899    \n",
      "Epoch 22/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9537 - acc: 0.6947Epoch 00021: acc improved from 0.68995 to 0.69421, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.9551 - acc: 0.6942    \n",
      "Epoch 23/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9675 - acc: 0.6846Epoch 00022: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9662 - acc: 0.6849    \n",
      "Epoch 24/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8670 - acc: 0.7101Epoch 00023: acc improved from 0.69421 to 0.71015, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.8664 - acc: 0.7102    \n",
      "Epoch 25/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.6985Epoch 00024: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8861 - acc: 0.6982    \n",
      "Epoch 26/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8741 - acc: 0.6921Epoch 00025: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8737 - acc: 0.6924    \n",
      "Epoch 27/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8701 - acc: 0.7109Epoch 00026: acc improved from 0.71015 to 0.71086, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.8700 - acc: 0.7109    \n",
      "Epoch 28/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8261 - acc: 0.7144Epoch 00027: acc improved from 0.71086 to 0.71431, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.8262 - acc: 0.7143    \n",
      "Epoch 29/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7985 - acc: 0.7209Epoch 00028: acc improved from 0.71431 to 0.72092, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.7985 - acc: 0.7209    \n",
      "Epoch 30/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.1874 - acc: 0.6788Epoch 00029: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.1857 - acc: 0.6789    \n",
      "Epoch 31/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9238 - acc: 0.7147Epoch 00030: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9229 - acc: 0.7148    \n",
      "Epoch 32/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9465 - acc: 0.7108Epoch 00031: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.9445 - acc: 0.7111    \n",
      "Epoch 33/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8257 - acc: 0.7295Epoch 00032: acc improved from 0.72092 to 0.72967, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.8257 - acc: 0.7297    \n",
      "Epoch 34/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8061 - acc: 0.7275Epoch 00033: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8059 - acc: 0.7275    \n",
      "Epoch 35/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9064 - acc: 0.7178Epoch 00034: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.9116 - acc: 0.7171    \n",
      "Epoch 36/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9841 - acc: 0.7036Epoch 00035: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9823 - acc: 0.7039    \n",
      "Epoch 37/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8178 - acc: 0.7311Epoch 00036: acc improved from 0.72967 to 0.73108, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.8173 - acc: 0.7311    \n",
      "Epoch 38/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7761 - acc: 0.7387Epoch 00037: acc improved from 0.73108 to 0.73858, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.7769 - acc: 0.7386    \n",
      "Epoch 39/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8119 - acc: 0.7380Epoch 00038: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8118 - acc: 0.7380    \n",
      "Epoch 40/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7892 - acc: 0.7428Epoch 00039: acc improved from 0.73858 to 0.74293, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.7887 - acc: 0.7429    \n",
      "Epoch 41/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8010 - acc: 0.7486Epoch 00040: acc improved from 0.74293 to 0.74773, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.8043 - acc: 0.7477    \n",
      "Epoch 42/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8970 - acc: 0.7128Epoch 00041: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8963 - acc: 0.7131    \n",
      "Epoch 43/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8085 - acc: 0.7435Epoch 00042: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8078 - acc: 0.7437    \n",
      "Epoch 44/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9185 - acc: 0.7325Epoch 00043: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9170 - acc: 0.7327    \n",
      "Epoch 45/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7765 - acc: 0.7574Epoch 00044: acc improved from 0.74773 to 0.75757, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.7759 - acc: 0.7576    \n",
      "Epoch 46/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7640 - acc: 0.7588Epoch 00045: acc improved from 0.75757 to 0.75893, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.7636 - acc: 0.7589    \n",
      "Epoch 47/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9107 - acc: 0.7339Epoch 00046: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9109 - acc: 0.7340    \n",
      "Epoch 48/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9007 - acc: 0.7328Epoch 00047: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9006 - acc: 0.7330    \n",
      "Epoch 49/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9610 - acc: 0.7250Epoch 00048: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.9600 - acc: 0.7252    \n",
      "Epoch 50/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.2143 - acc: 0.6826Epoch 00049: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.2166 - acc: 0.6812    \n",
      "Epoch 51/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.1574 - acc: 0.6371Epoch 00050: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.1550 - acc: 0.6378    \n",
      "Epoch 52/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7217Epoch 00051: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.8745 - acc: 0.7220    \n",
      "Epoch 53/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9357 - acc: 0.7211Epoch 00052: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9480 - acc: 0.7197    \n",
      "Epoch 54/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.5607 - acc: 0.6321Epoch 00053: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.5644 - acc: 0.6318    \n",
      "Epoch 55/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.5861 - acc: 0.6269Epoch 00054: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.5829 - acc: 0.6273    \n",
      "Epoch 56/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.3659 - acc: 0.6443Epoch 00055: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.3637 - acc: 0.6446    \n",
      "Epoch 57/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.1543 - acc: 0.6652Epoch 00056: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.1543 - acc: 0.6654    \n",
      "Epoch 58/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0439 - acc: 0.6827Epoch 00057: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0428 - acc: 0.6828    \n",
      "Epoch 59/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.6968Epoch 00058: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.9640 - acc: 0.6970    \n",
      "Epoch 60/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0899 - acc: 0.6516Epoch 00059: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 1.0885 - acc: 0.6520    \n",
      "Epoch 61/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0244 - acc: 0.6884Epoch 00060: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0233 - acc: 0.6886    \n",
      "Epoch 62/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9755 - acc: 0.6990Epoch 00061: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9754 - acc: 0.6992    \n",
      "Epoch 63/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9005 - acc: 0.7246Epoch 00062: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.9002 - acc: 0.7246    \n",
      "Epoch 64/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8404 - acc: 0.7397Epoch 00063: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8399 - acc: 0.7398    \n",
      "Epoch 65/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0932 - acc: 0.6856Epoch 00064: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0934 - acc: 0.6853    \n",
      "Epoch 66/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0612 - acc: 0.6892Epoch 00065: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 66s - loss: 1.0618 - acc: 0.6893    \n",
      "Epoch 67/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9927 - acc: 0.7088Epoch 00066: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9917 - acc: 0.7090    \n",
      "Epoch 68/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9997 - acc: 0.7069Epoch 00067: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9985 - acc: 0.7071    \n",
      "Epoch 69/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8483 - acc: 0.7305Epoch 00068: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8476 - acc: 0.7306    \n",
      "Epoch 70/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8165 - acc: 0.7357Epoch 00069: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8164 - acc: 0.7357    \n",
      "Epoch 71/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7826 - acc: 0.7451Epoch 00070: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.7829 - acc: 0.7450    \n",
      "Epoch 72/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8368 - acc: 0.7395Epoch 00071: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.8354 - acc: 0.7399    \n",
      "Epoch 73/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7657 - acc: 0.7596Epoch 00072: acc improved from 0.75893 to 0.75951, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.7658 - acc: 0.7595    \n",
      "Epoch 74/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7232 - acc: 0.7636Epoch 00073: acc improved from 0.75951 to 0.76363, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.7234 - acc: 0.7636    \n",
      "Epoch 75/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.7647Epoch 00074: acc improved from 0.76363 to 0.76459, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.7476 - acc: 0.7646    \n",
      "Epoch 76/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7308 - acc: 0.7661Epoch 00075: acc improved from 0.76459 to 0.76618, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.7307 - acc: 0.7662    \n",
      "Epoch 77/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6729 - acc: 0.7791Epoch 00076: acc improved from 0.76618 to 0.77905, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.6728 - acc: 0.7790    \n",
      "Epoch 78/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6639 - acc: 0.7837Epoch 00077: acc improved from 0.77905 to 0.78377, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.6639 - acc: 0.7838    \n",
      "Epoch 79/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.7900Epoch 00078: acc improved from 0.78377 to 0.79006, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.6455 - acc: 0.7901    \n",
      "Epoch 80/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6102 - acc: 0.7980Epoch 00079: acc improved from 0.79006 to 0.79809, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.6098 - acc: 0.7981    \n",
      "Epoch 81/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.8030Epoch 00080: acc improved from 0.79809 to 0.80295, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.6006 - acc: 0.8029    \n",
      "Epoch 82/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.7976Epoch 00081: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6348 - acc: 0.7973    \n",
      "Epoch 83/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6445 - acc: 0.7936Epoch 00082: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6439 - acc: 0.7938    \n",
      "Epoch 84/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6065 - acc: 0.8021Epoch 00083: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6068 - acc: 0.8021    \n",
      "Epoch 85/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7702 - acc: 0.7485Epoch 00084: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7693 - acc: 0.7488    \n",
      "Epoch 86/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6870 - acc: 0.7801Epoch 00085: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6878 - acc: 0.7800    \n",
      "Epoch 87/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6354 - acc: 0.7997Epoch 00086: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6352 - acc: 0.7998    \n",
      "Epoch 88/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5866 - acc: 0.8121Epoch 00087: acc improved from 0.80295 to 0.81218, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.5866 - acc: 0.8122    \n",
      "Epoch 89/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.8194Epoch 00088: acc improved from 0.81218 to 0.81946, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.5633 - acc: 0.8195    \n",
      "Epoch 90/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9573 - acc: 0.7303Epoch 00089: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9595 - acc: 0.7296    \n",
      "Epoch 91/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9110 - acc: 0.7369Epoch 00090: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9087 - acc: 0.7375    \n",
      "Epoch 92/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7632 - acc: 0.7777Epoch 00091: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7624 - acc: 0.7778    \n",
      "Epoch 93/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6957 - acc: 0.7927Epoch 00092: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6957 - acc: 0.7928    \n",
      "Epoch 94/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6481 - acc: 0.7983Epoch 00093: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6478 - acc: 0.7983    \n",
      "Epoch 95/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.8020Epoch 00094: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6279 - acc: 0.8021    \n",
      "Epoch 96/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5847 - acc: 0.8142Epoch 00095: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5843 - acc: 0.8143    \n",
      "Epoch 97/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.8025Epoch 00096: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6110 - acc: 0.8024    \n",
      "Epoch 98/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6801 - acc: 0.7882Epoch 00097: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6791 - acc: 0.7885    \n",
      "Epoch 99/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.8112Epoch 00098: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6329 - acc: 0.8113    \n",
      "Epoch 100/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.8058Epoch 00099: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6672 - acc: 0.8060    \n",
      "Epoch 101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.8181Epoch 00100: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5752 - acc: 0.8182    \n",
      "Epoch 102/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8312Epoch 00101: acc improved from 0.81946 to 0.83127, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.5435 - acc: 0.8313    \n",
      "Epoch 103/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5158 - acc: 0.8386Epoch 00102: acc improved from 0.83127 to 0.83868, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.5156 - acc: 0.8387    \n",
      "Epoch 104/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4904 - acc: 0.8438Epoch 00103: acc improved from 0.83868 to 0.84382, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4903 - acc: 0.8438    \n",
      "Epoch 105/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8480Epoch 00104: acc improved from 0.84382 to 0.84809, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4820 - acc: 0.8481    \n",
      "Epoch 106/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4815 - acc: 0.8499Epoch 00105: acc improved from 0.84809 to 0.84997, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4812 - acc: 0.8500    \n",
      "Epoch 107/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8547Epoch 00106: acc improved from 0.84997 to 0.85451, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4639 - acc: 0.8545    \n",
      "Epoch 108/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4922 - acc: 0.8526Epoch 00107: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4924 - acc: 0.8526    \n",
      "Epoch 109/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8156Epoch 00108: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5614 - acc: 0.8160    \n",
      "Epoch 110/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.8435Epoch 00109: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4920 - acc: 0.8435    \n",
      "Epoch 111/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.8386Epoch 00110: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5369 - acc: 0.8387    \n",
      "Epoch 112/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.8204Epoch 00111: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6151 - acc: 0.8196    \n",
      "Epoch 113/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7967 - acc: 0.7668Epoch 00112: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7954 - acc: 0.7670    \n",
      "Epoch 114/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6869 - acc: 0.7790Epoch 00113: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6866 - acc: 0.7791    \n",
      "Epoch 115/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6806 - acc: 0.7868Epoch 00114: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6801 - acc: 0.7871    \n",
      "Epoch 116/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6341 - acc: 0.8077Epoch 00115: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6339 - acc: 0.8077    \n",
      "Epoch 117/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.8162Epoch 00116: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6310 - acc: 0.8163    \n",
      "Epoch 118/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5906 - acc: 0.8266Epoch 00117: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5906 - acc: 0.8267    \n",
      "Epoch 119/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.8335Epoch 00118: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5599 - acc: 0.8335    \n",
      "Epoch 120/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5728 - acc: 0.8336Epoch 00119: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5747 - acc: 0.8333    \n",
      "Epoch 121/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6393 - acc: 0.8194Epoch 00120: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6394 - acc: 0.8194    \n",
      "Epoch 122/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.8312Epoch 00121: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5820 - acc: 0.8313    \n",
      "Epoch 123/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5231 - acc: 0.8442Epoch 00122: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5235 - acc: 0.8441    \n",
      "Epoch 124/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.8489Epoch 00123: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5091 - acc: 0.8489    \n",
      "Epoch 125/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4824 - acc: 0.8539Epoch 00124: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4825 - acc: 0.8538    \n",
      "Epoch 126/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8581Epoch 00125: acc improved from 0.85451 to 0.85811, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4574 - acc: 0.8581    \n",
      "Epoch 127/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6425 - acc: 0.8203Epoch 00126: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6440 - acc: 0.8199    \n",
      "Epoch 128/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7059 - acc: 0.7991Epoch 00127: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7063 - acc: 0.7989    \n",
      "Epoch 129/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 1.0361 - acc: 0.7369Epoch 00128: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 1.0371 - acc: 0.7366    \n",
      "Epoch 130/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.7475Epoch 00129: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.8835 - acc: 0.7477    \n",
      "Epoch 131/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7409 - acc: 0.7711Epoch 00130: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.7405 - acc: 0.7711    \n",
      "Epoch 132/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7159 - acc: 0.7722Epoch 00131: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7154 - acc: 0.7724    \n",
      "Epoch 133/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6421 - acc: 0.7899Epoch 00132: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6417 - acc: 0.7900    \n",
      "Epoch 134/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.8061Epoch 00133: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5947 - acc: 0.8062    \n",
      "Epoch 135/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5781 - acc: 0.8134Epoch 00134: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5779 - acc: 0.8134    \n",
      "Epoch 136/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5516 - acc: 0.8206Epoch 00135: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5521 - acc: 0.8204    \n",
      "Epoch 137/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5654 - acc: 0.8165Epoch 00136: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5655 - acc: 0.8165    \n",
      "Epoch 138/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.8192Epoch 00137: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5300 - acc: 0.8193    \n",
      "Epoch 139/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5519 - acc: 0.8209Epoch 00138: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5522 - acc: 0.8210    \n",
      "Epoch 140/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.8256Epoch 00139: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5446 - acc: 0.8255    \n",
      "Epoch 141/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8266Epoch 00140: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5461 - acc: 0.8267    \n",
      "Epoch 142/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.8331Epoch 00141: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5188 - acc: 0.8331    \n",
      "Epoch 143/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.8384Epoch 00142: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5008 - acc: 0.8384    \n",
      "Epoch 144/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4907 - acc: 0.8428Epoch 00143: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4908 - acc: 0.8427    \n",
      "Epoch 145/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5286 - acc: 0.8366Epoch 00144: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5288 - acc: 0.8367    \n",
      "Epoch 146/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.8427Epoch 00145: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5084 - acc: 0.8427    \n",
      "Epoch 147/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8489Epoch 00146: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4821 - acc: 0.8489    \n",
      "Epoch 148/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8560Epoch 00147: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4494 - acc: 0.8561    \n",
      "Epoch 149/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8581Epoch 00148: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4439 - acc: 0.8580    \n",
      "Epoch 150/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8617Epoch 00149: acc improved from 0.85811 to 0.86169, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4334 - acc: 0.8617    \n",
      "Epoch 151/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5297 - acc: 0.8263Epoch 00150: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5315 - acc: 0.8257    \n",
      "Epoch 152/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6210 - acc: 0.7946Epoch 00151: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6206 - acc: 0.7948    \n",
      "Epoch 153/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5831 - acc: 0.8138Epoch 00152: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5826 - acc: 0.8140    \n",
      "Epoch 154/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.8350Epoch 00153: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5557 - acc: 0.8351    \n",
      "Epoch 155/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4948 - acc: 0.8506Epoch 00154: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4946 - acc: 0.8507    \n",
      "Epoch 156/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8597Epoch 00155: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4665 - acc: 0.8598    \n",
      "Epoch 157/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8681Epoch 00156: acc improved from 0.86169 to 0.86821, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4271 - acc: 0.8682    \n",
      "Epoch 158/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8730Epoch 00157: acc improved from 0.86821 to 0.87310, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.4124 - acc: 0.8731    \n",
      "Epoch 159/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8753Epoch 00158: acc improved from 0.87310 to 0.87517, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.4063 - acc: 0.8752    \n",
      "Epoch 160/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8698Epoch 00159: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4361 - acc: 0.8695    \n",
      "Epoch 161/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4901 - acc: 0.8541Epoch 00160: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4896 - acc: 0.8542    \n",
      "Epoch 162/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8636Epoch 00161: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4476 - acc: 0.8637    \n",
      "Epoch 163/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4330 - acc: 0.8690Epoch 00162: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4327 - acc: 0.8690    \n",
      "Epoch 164/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3983 - acc: 0.8778Epoch 00163: acc improved from 0.87517 to 0.87778, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.3984 - acc: 0.8778    \n",
      "Epoch 165/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8826Epoch 00164: acc improved from 0.87778 to 0.88257, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3886 - acc: 0.8826    \n",
      "Epoch 166/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.8689Epoch 00165: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4152 - acc: 0.8683    \n",
      "Epoch 167/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4632 - acc: 0.8415Epoch 00166: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4628 - acc: 0.8417    \n",
      "Epoch 168/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8730Epoch 00167: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4069 - acc: 0.8730    \n",
      "Epoch 169/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8809Epoch 00168: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3879 - acc: 0.8809    \n",
      "Epoch 170/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4254 - acc: 0.8731Epoch 00169: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4256 - acc: 0.8729    \n",
      "Epoch 171/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8596Epoch 00170: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 65s - loss: 0.4699 - acc: 0.8595    \n",
      "Epoch 172/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.8100Epoch 00171: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6045 - acc: 0.8101    \n",
      "Epoch 173/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6138 - acc: 0.8278Epoch 00172: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6129 - acc: 0.8280    \n",
      "Epoch 174/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8199Epoch 00173: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5847 - acc: 0.8197    \n",
      "Epoch 175/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.8148Epoch 00174: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6147 - acc: 0.8150    \n",
      "Epoch 176/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5041 - acc: 0.8445Epoch 00175: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5035 - acc: 0.8446    \n",
      "Epoch 177/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8576Epoch 00176: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4453 - acc: 0.8577    \n",
      "Epoch 178/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8611Epoch 00177: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4379 - acc: 0.8612    \n",
      "Epoch 179/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4192 - acc: 0.8707Epoch 00178: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4194 - acc: 0.8707    \n",
      "Epoch 180/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8675Epoch 00179: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4241 - acc: 0.8675    \n",
      "Epoch 181/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8725Epoch 00180: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4207 - acc: 0.8727    \n",
      "Epoch 182/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8842Epoch 00181: acc improved from 0.88257 to 0.88425, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3779 - acc: 0.8842    \n",
      "Epoch 183/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3527 - acc: 0.8918Epoch 00182: acc improved from 0.88425 to 0.89181, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3530 - acc: 0.8918    \n",
      "Epoch 184/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8666Epoch 00183: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4376 - acc: 0.8664    \n",
      "Epoch 185/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.8677Epoch 00184: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4244 - acc: 0.8679    \n",
      "Epoch 186/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8681Epoch 00185: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4626 - acc: 0.8682    \n",
      "Epoch 187/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8739Epoch 00186: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4242 - acc: 0.8740    \n",
      "Epoch 188/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8881Epoch 00187: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3741 - acc: 0.8882    \n",
      "Epoch 189/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3823 - acc: 0.8751Epoch 00188: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3818 - acc: 0.8753    \n",
      "Epoch 190/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3418 - acc: 0.8912Epoch 00189: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3418 - acc: 0.8913    \n",
      "Epoch 191/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.8955Epoch 00190: acc improved from 0.89181 to 0.89556, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3409 - acc: 0.8956    \n",
      "Epoch 192/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3772 - acc: 0.8899Epoch 00191: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3781 - acc: 0.8896    \n",
      "Epoch 193/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8608Epoch 00192: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4576 - acc: 0.8609    \n",
      "Epoch 194/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8779Epoch 00193: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3919 - acc: 0.8779    \n",
      "Epoch 195/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3539 - acc: 0.8877Epoch 00194: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3538 - acc: 0.8877    \n",
      "Epoch 196/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3375 - acc: 0.8929Epoch 00195: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3375 - acc: 0.8928    \n",
      "Epoch 197/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3637 - acc: 0.8908Epoch 00196: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3640 - acc: 0.8908    \n",
      "Epoch 198/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4335 - acc: 0.8766Epoch 00197: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4329 - acc: 0.8767    \n",
      "Epoch 199/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4307 - acc: 0.8753Epoch 00198: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4309 - acc: 0.8752    \n",
      "Epoch 200/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8781Epoch 00199: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4228 - acc: 0.8782    \n",
      "Epoch 201/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8770Epoch 00200: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4242 - acc: 0.8767    \n",
      "Epoch 202/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8806Epoch 00201: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4003 - acc: 0.8808    \n",
      "Epoch 203/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3487 - acc: 0.8956Epoch 00202: acc improved from 0.89556 to 0.89564, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.3486 - acc: 0.8956    \n",
      "Epoch 204/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8944Epoch 00203: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3709 - acc: 0.8943    \n",
      "Epoch 205/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8738Epoch 00204: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4432 - acc: 0.8740    \n",
      "Epoch 206/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3925 - acc: 0.8881Epoch 00205: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3920 - acc: 0.8882    \n",
      "Epoch 207/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3717 - acc: 0.8936Epoch 00206: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3715 - acc: 0.8937    \n",
      "Epoch 208/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.9014Epoch 00207: acc improved from 0.89564 to 0.90138, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3449 - acc: 0.9014    \n",
      "Epoch 209/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6990 - acc: 0.8335Epoch 00208: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6983 - acc: 0.8334    \n",
      "Epoch 210/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5768 - acc: 0.8471Epoch 00209: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5758 - acc: 0.8473    \n",
      "Epoch 211/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4983 - acc: 0.8617Epoch 00210: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4989 - acc: 0.8615    \n",
      "Epoch 212/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4773 - acc: 0.8666Epoch 00211: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4786 - acc: 0.8664    \n",
      "Epoch 213/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.8435Epoch 00212: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5763 - acc: 0.8436    \n",
      "Epoch 214/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.8668Epoch 00213: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4793 - acc: 0.8669    \n",
      "Epoch 215/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8804Epoch 00214: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4239 - acc: 0.8804    \n",
      "Epoch 216/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8823Epoch 00215: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4123 - acc: 0.8823    \n",
      "Epoch 217/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3887 - acc: 0.8873Epoch 00216: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3887 - acc: 0.8873    \n",
      "Epoch 218/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3669 - acc: 0.8949Epoch 00217: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3669 - acc: 0.8949    \n",
      "Epoch 219/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8961Epoch 00218: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3638 - acc: 0.8962    \n",
      "Epoch 220/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8986Epoch 00219: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3624 - acc: 0.8987    \n",
      "Epoch 221/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.9085Epoch 00220: acc improved from 0.90138 to 0.90857, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3372 - acc: 0.9086    \n",
      "Epoch 222/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9144Epoch 00221: acc improved from 0.90857 to 0.91443, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3164 - acc: 0.9144    \n",
      "Epoch 223/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3027 - acc: 0.9189Epoch 00222: acc improved from 0.91443 to 0.91889, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.3030 - acc: 0.9189    \n",
      "Epoch 224/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.9208Epoch 00223: acc improved from 0.91889 to 0.92083, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.3060 - acc: 0.9208    \n",
      "Epoch 225/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.9247Epoch 00224: acc improved from 0.92083 to 0.92470, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2880 - acc: 0.9247    \n",
      "Epoch 226/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.9253Epoch 00225: acc improved from 0.92470 to 0.92530, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.2932 - acc: 0.9253    \n",
      "Epoch 227/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9274Epoch 00226: acc improved from 0.92530 to 0.92737, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2837 - acc: 0.9274    \n",
      "Epoch 228/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.9285Epoch 00227: acc improved from 0.92737 to 0.92853, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2786 - acc: 0.9285    \n",
      "Epoch 229/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9286Epoch 00228: acc improved from 0.92853 to 0.92856, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2818 - acc: 0.9286    \n",
      "Epoch 230/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.9254Epoch 00229: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2999 - acc: 0.9253    \n",
      "Epoch 231/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9235Epoch 00230: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3076 - acc: 0.9235    \n",
      "Epoch 232/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9254Epoch 00231: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2986 - acc: 0.9254    \n",
      "Epoch 233/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9298Epoch 00232: acc improved from 0.92856 to 0.92987, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2838 - acc: 0.9299    \n",
      "Epoch 234/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9350Epoch 00233: acc improved from 0.92987 to 0.93504, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2620 - acc: 0.9350    \n",
      "Epoch 235/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9387Epoch 00234: acc improved from 0.93504 to 0.93869, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.2496 - acc: 0.9387    \n",
      "Epoch 236/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.9358Epoch 00235: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2590 - acc: 0.9358    \n",
      "Epoch 237/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9385Epoch 00236: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2502 - acc: 0.9385    \n",
      "Epoch 238/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9416Epoch 00237: acc improved from 0.93869 to 0.94151, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2412 - acc: 0.9415    \n",
      "Epoch 239/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9379Epoch 00238: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2594 - acc: 0.9379    \n",
      "Epoch 240/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9353Epoch 00239: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2744 - acc: 0.9353    \n",
      "Epoch 241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9388Epoch 00240: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2594 - acc: 0.9389    \n",
      "Epoch 242/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9435Epoch 00241: acc improved from 0.94151 to 0.94343, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2398 - acc: 0.9434    \n",
      "Epoch 243/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2379 - acc: 0.9449Epoch 00242: acc improved from 0.94343 to 0.94482, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.2382 - acc: 0.9448    \n",
      "Epoch 244/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9444Epoch 00243: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2391 - acc: 0.9444    \n",
      "Epoch 245/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9378Epoch 00244: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2585 - acc: 0.9378    \n",
      "Epoch 246/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9379Epoch 00245: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2596 - acc: 0.9380    \n",
      "Epoch 247/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.9260Epoch 00246: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3168 - acc: 0.9255    \n",
      "Epoch 248/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.9063Epoch 00247: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3776 - acc: 0.9064    \n",
      "Epoch 249/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3131 - acc: 0.9240Epoch 00248: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3129 - acc: 0.9240    \n",
      "Epoch 250/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2857 - acc: 0.9314Epoch 00249: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2858 - acc: 0.9314    \n",
      "Epoch 251/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.9231Epoch 00250: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3187 - acc: 0.9232    \n",
      "Epoch 252/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.9312Epoch 00251: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2859 - acc: 0.9313    \n",
      "Epoch 253/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9360Epoch 00252: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2708 - acc: 0.9360    \n",
      "Epoch 254/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9379Epoch 00253: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2647 - acc: 0.9379    \n",
      "Epoch 255/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.9405Epoch 00254: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2562 - acc: 0.9405    \n",
      "Epoch 256/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2566 - acc: 0.9410Epoch 00255: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2566 - acc: 0.9410    \n",
      "Epoch 257/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.9239Epoch 00256: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2988 - acc: 0.9238    \n",
      "Epoch 258/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.9214Epoch 00257: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2962 - acc: 0.9214    \n",
      "Epoch 259/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.9238Epoch 00258: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3463 - acc: 0.9234    \n",
      "Epoch 260/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3736 - acc: 0.9114Epoch 00259: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3734 - acc: 0.9115    \n",
      "Epoch 261/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8950Epoch 00260: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4474 - acc: 0.8951    \n",
      "Epoch 262/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.9157Epoch 00261: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3551 - acc: 0.9157    \n",
      "Epoch 263/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.9268Epoch 00262: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3151 - acc: 0.9268    \n",
      "Epoch 264/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3455 - acc: 0.9215Epoch 00263: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3456 - acc: 0.9214    \n",
      "Epoch 265/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3126 - acc: 0.9266Epoch 00264: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3126 - acc: 0.9266    \n",
      "Epoch 266/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9333Epoch 00265: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2958 - acc: 0.9332    \n",
      "Epoch 267/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2959 - acc: 0.9336Epoch 00266: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2958 - acc: 0.9337    \n",
      "Epoch 268/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.9263Epoch 00267: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3222 - acc: 0.9262    \n",
      "Epoch 269/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.9179Epoch 00268: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3567 - acc: 0.9179    \n",
      "Epoch 270/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9268Epoch 00269: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3211 - acc: 0.9268    \n",
      "Epoch 271/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4192 - acc: 0.9044Epoch 00270: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4199 - acc: 0.9042    \n",
      "Epoch 272/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.9057Epoch 00271: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4140 - acc: 0.9057    \n",
      "Epoch 273/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.9169Epoch 00272: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3603 - acc: 0.9170    \n",
      "Epoch 274/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.9272Epoch 00273: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3201 - acc: 0.9272    \n",
      "Epoch 275/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3020 - acc: 0.9323Epoch 00274: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3019 - acc: 0.9323    \n",
      "Epoch 276/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2935 - acc: 0.9350Epoch 00275: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2933 - acc: 0.9350    \n",
      "Epoch 277/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9382Epoch 00276: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2800 - acc: 0.9382    \n",
      "Epoch 278/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2749 - acc: 0.9395Epoch 00277: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2748 - acc: 0.9395    \n",
      "Epoch 279/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9393Epoch 00278: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2741 - acc: 0.9393    \n",
      "Epoch 280/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9409Epoch 00279: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2687 - acc: 0.9408    \n",
      "Epoch 281/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.9295Epoch 00280: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3160 - acc: 0.9295    \n",
      "Epoch 282/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.9321Epoch 00281: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3040 - acc: 0.9322    \n",
      "Epoch 283/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.9346Epoch 00282: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2922 - acc: 0.9346    \n",
      "Epoch 284/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3042 - acc: 0.9316Epoch 00283: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3052 - acc: 0.9313    \n",
      "Epoch 285/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.9196Epoch 00284: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3553 - acc: 0.9197    \n",
      "Epoch 286/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.9288Epoch 00285: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3196 - acc: 0.9288    \n",
      "Epoch 287/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9347Epoch 00286: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2966 - acc: 0.9348    \n",
      "Epoch 288/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.9396Epoch 00287: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2768 - acc: 0.9396    \n",
      "Epoch 289/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2676 - acc: 0.9416Epoch 00288: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2677 - acc: 0.9416    \n",
      "Epoch 290/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.9428Epoch 00289: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2708 - acc: 0.9425    \n",
      "Epoch 291/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.9177Epoch 00290: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3674 - acc: 0.9178    \n",
      "Epoch 292/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.9294Epoch 00291: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3246 - acc: 0.9295    \n",
      "Epoch 293/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.9354Epoch 00292: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2916 - acc: 0.9354    \n",
      "Epoch 294/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.9403Epoch 00293: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2751 - acc: 0.9403    \n",
      "Epoch 295/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.9386Epoch 00294: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2826 - acc: 0.9385    \n",
      "Epoch 296/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9392Epoch 00295: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2811 - acc: 0.9392    \n",
      "Epoch 297/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9415Epoch 00296: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2710 - acc: 0.9414    \n",
      "Epoch 298/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3042 - acc: 0.9364Epoch 00297: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3045 - acc: 0.9364    \n",
      "Epoch 299/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.9258Epoch 00298: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3566 - acc: 0.9257    \n",
      "Epoch 300/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.9229Epoch 00299: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3705 - acc: 0.9230    \n",
      "Epoch 301/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.9345Epoch 00300: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3186 - acc: 0.9345    \n",
      "Epoch 302/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.9363Epoch 00301: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3122 - acc: 0.9363    \n",
      "Epoch 303/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.9352Epoch 00302: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3213 - acc: 0.9352    \n",
      "Epoch 304/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.9359Epoch 00303: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3149 - acc: 0.9359    \n",
      "Epoch 305/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5635 - acc: 0.8655Epoch 00304: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5639 - acc: 0.8654    \n",
      "Epoch 306/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8672Epoch 00305: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5358 - acc: 0.8674    \n",
      "Epoch 307/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4625 - acc: 0.8824Epoch 00306: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4624 - acc: 0.8825    \n",
      "Epoch 308/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8839Epoch 00307: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4616 - acc: 0.8840    \n",
      "Epoch 309/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8879Epoch 00308: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4553 - acc: 0.8877    \n",
      "Epoch 310/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8892Epoch 00309: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4681 - acc: 0.8894    \n",
      "Epoch 311/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3928 - acc: 0.9123Epoch 00310: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3926 - acc: 0.9124    \n",
      "Epoch 312/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.9227Epoch 00311: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3608 - acc: 0.9227    \n",
      "Epoch 313/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3450 - acc: 0.9272Epoch 00312: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3446 - acc: 0.9273    \n",
      "Epoch 314/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.9314Epoch 00313: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 66s - loss: 0.3326 - acc: 0.9314    \n",
      "Epoch 315/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.9215Epoch 00314: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3845 - acc: 0.9213    \n",
      "Epoch 316/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.9124Epoch 00315: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4136 - acc: 0.9125    \n",
      "Epoch 317/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3509 - acc: 0.9256Epoch 00316: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3507 - acc: 0.9257    \n",
      "Epoch 318/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.9320Epoch 00317: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3257 - acc: 0.9319    \n",
      "Epoch 319/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3227 - acc: 0.9330Epoch 00318: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3227 - acc: 0.9330    \n",
      "Epoch 320/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.9231Epoch 00319: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3643 - acc: 0.9230    \n",
      "Epoch 321/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3611 - acc: 0.9235Epoch 00320: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3610 - acc: 0.9235    \n",
      "Epoch 322/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3350 - acc: 0.9305Epoch 00321: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3351 - acc: 0.9305    \n",
      "Epoch 323/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.9334Epoch 00322: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3256 - acc: 0.9335    \n",
      "Epoch 324/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3247 - acc: 0.9331Epoch 00323: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3250 - acc: 0.9330    \n",
      "Epoch 325/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4603 - acc: 0.9017Epoch 00324: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4618 - acc: 0.9011    \n",
      "Epoch 326/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8813Epoch 00325: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4820 - acc: 0.8814    \n",
      "Epoch 327/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.9078Epoch 00326: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3880 - acc: 0.9079    \n",
      "Epoch 328/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.9116Epoch 00327: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3709 - acc: 0.9115    \n",
      "Epoch 329/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.9125Epoch 00328: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3716 - acc: 0.9125    \n",
      "Epoch 330/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.9223Epoch 00329: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3399 - acc: 0.9223    \n",
      "Epoch 331/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.9296Epoch 00330: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3215 - acc: 0.9297    \n",
      "Epoch 332/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9350Epoch 00331: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3074 - acc: 0.9350    \n",
      "Epoch 333/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9384Epoch 00332: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2938 - acc: 0.9384    \n",
      "Epoch 334/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9399Epoch 00333: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2890 - acc: 0.9399    \n",
      "Epoch 335/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9394Epoch 00334: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2899 - acc: 0.9394    \n",
      "Epoch 336/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9420Epoch 00335: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2806 - acc: 0.9420    \n",
      "Epoch 337/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.9428Epoch 00336: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2790 - acc: 0.9427    \n",
      "Epoch 338/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9371Epoch 00337: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3057 - acc: 0.9371    \n",
      "Epoch 339/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3140 - acc: 0.9366Epoch 00338: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3138 - acc: 0.9366    \n",
      "Epoch 340/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9421Epoch 00339: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2823 - acc: 0.9421    \n",
      "Epoch 341/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4051 - acc: 0.9168Epoch 00340: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4048 - acc: 0.9169    \n",
      "Epoch 342/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.9309Epoch 00341: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3357 - acc: 0.9310    \n",
      "Epoch 343/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6878 - acc: 0.8531Epoch 00342: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6869 - acc: 0.8532    \n",
      "Epoch 344/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.8742Epoch 00343: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5516 - acc: 0.8743    \n",
      "Epoch 345/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.8865Epoch 00344: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4854 - acc: 0.8865    \n",
      "Epoch 346/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8969Epoch 00345: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4427 - acc: 0.8970    \n",
      "Epoch 347/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8942Epoch 00346: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4598 - acc: 0.8939    \n",
      "Epoch 348/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8856Epoch 00347: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4792 - acc: 0.8857    \n",
      "Epoch 349/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4994 - acc: 0.8786Epoch 00348: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4991 - acc: 0.8787    \n",
      "Epoch 350/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8914Epoch 00349: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4479 - acc: 0.8915    \n",
      "Epoch 351/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4033 - acc: 0.9025Epoch 00350: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4030 - acc: 0.9025    \n",
      "Epoch 352/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.9124Epoch 00351: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3575 - acc: 0.9124    \n",
      "Epoch 353/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.9159Epoch 00352: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3442 - acc: 0.9159    \n",
      "Epoch 354/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.9189Epoch 00353: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3367 - acc: 0.9188    \n",
      "Epoch 355/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.9169Epoch 00354: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3469 - acc: 0.9170    \n",
      "Epoch 356/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.9228Epoch 00355: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3254 - acc: 0.9228    \n",
      "Epoch 357/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.9266Epoch 00356: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3095 - acc: 0.9265    \n",
      "Epoch 358/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.9218Epoch 00357: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3363 - acc: 0.9216    \n",
      "Epoch 359/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.9157Epoch 00358: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3748 - acc: 0.9158    \n",
      "Epoch 360/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.9221Epoch 00359: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3430 - acc: 0.9218    \n",
      "Epoch 361/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8909Epoch 00360: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4576 - acc: 0.8910    \n",
      "Epoch 362/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3824 - acc: 0.9096Epoch 00361: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3823 - acc: 0.9097    \n",
      "Epoch 363/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.9177Epoch 00362: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3525 - acc: 0.9177    \n",
      "Epoch 364/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3455 - acc: 0.9203Epoch 00363: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3455 - acc: 0.9203    \n",
      "Epoch 365/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3614 - acc: 0.9176Epoch 00364: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3618 - acc: 0.9176    \n",
      "Epoch 366/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.9180Epoch 00365: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3658 - acc: 0.9180    \n",
      "Epoch 367/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3439 - acc: 0.9242Epoch 00366: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3438 - acc: 0.9243    \n",
      "Epoch 368/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.9258Epoch 00367: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3382 - acc: 0.9258    \n",
      "Epoch 369/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3296 - acc: 0.9276Epoch 00368: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3294 - acc: 0.9277    \n",
      "Epoch 370/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.9302Epoch 00369: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3188 - acc: 0.9303    \n",
      "Epoch 371/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.9316Epoch 00370: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3129 - acc: 0.9316    \n",
      "Epoch 372/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.9321Epoch 00371: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3112 - acc: 0.9321    \n",
      "Epoch 373/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3018 - acc: 0.9343Epoch 00372: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3018 - acc: 0.9343    \n",
      "Epoch 374/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.9325Epoch 00373: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3085 - acc: 0.9324    \n",
      "Epoch 375/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.9295Epoch 00374: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3183 - acc: 0.9296    \n",
      "Epoch 376/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.9254Epoch 00375: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3383 - acc: 0.9253    \n",
      "Epoch 377/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.9291Epoch 00376: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3207 - acc: 0.9291    \n",
      "Epoch 378/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9344Epoch 00377: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2994 - acc: 0.9344    \n",
      "Epoch 379/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.9217Epoch 00378: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3518 - acc: 0.9212    \n",
      "Epoch 380/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.9014Epoch 00379: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4070 - acc: 0.9016    \n",
      "Epoch 381/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.9168Epoch 00380: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3632 - acc: 0.9169    \n",
      "Epoch 382/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9307Epoch 00381: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3173 - acc: 0.9307    \n",
      "Epoch 383/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3131 - acc: 0.9329Epoch 00382: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3132 - acc: 0.9329    \n",
      "Epoch 384/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.9327Epoch 00383: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3128 - acc: 0.9328    \n",
      "Epoch 385/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9389Epoch 00384: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2904 - acc: 0.9388    \n",
      "Epoch 386/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9389Epoch 00385: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2906 - acc: 0.9389    \n",
      "Epoch 387/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.9387Epoch 00386: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2854 - acc: 0.9388    \n",
      "Epoch 388/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.9441Epoch 00387: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 66s - loss: 0.2748 - acc: 0.9441    \n",
      "Epoch 389/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.9302Epoch 00388: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3393 - acc: 0.9303    \n",
      "Epoch 390/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.9384Epoch 00389: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3034 - acc: 0.9384    \n",
      "Epoch 391/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.9408Epoch 00390: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3021 - acc: 0.9408    \n",
      "Epoch 392/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.9449Epoch 00391: acc improved from 0.94482 to 0.94495, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2836 - acc: 0.9450    \n",
      "Epoch 393/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9479Epoch 00392: acc improved from 0.94495 to 0.94792, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2699 - acc: 0.9479    \n",
      "Epoch 394/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2857 - acc: 0.9446Epoch 00393: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2857 - acc: 0.9446    \n",
      "Epoch 395/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.9110Epoch 00394: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4318 - acc: 0.9110    \n",
      "Epoch 396/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.9106Epoch 00395: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4204 - acc: 0.9105    \n",
      "Epoch 397/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.8847Epoch 00396: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5466 - acc: 0.8846    \n",
      "Epoch 398/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8948Epoch 00397: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5037 - acc: 0.8949    \n",
      "Epoch 399/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.9092Epoch 00398: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.4379 - acc: 0.9092    \n",
      "Epoch 400/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.9135Epoch 00399: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4125 - acc: 0.9134    \n",
      "Epoch 401/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4000 - acc: 0.9161Epoch 00400: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3995 - acc: 0.9162    \n",
      "Epoch 402/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.9256Epoch 00401: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3579 - acc: 0.9256    \n",
      "Epoch 403/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3392 - acc: 0.9303Epoch 00402: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3392 - acc: 0.9303    \n",
      "Epoch 404/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.9314Epoch 00403: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3373 - acc: 0.9314    \n",
      "Epoch 405/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.9350 - acc: 0.8132Epoch 00404: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.9337 - acc: 0.8132    \n",
      "Epoch 406/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7728 - acc: 0.8221Epoch 00405: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.7716 - acc: 0.8223    \n",
      "Epoch 407/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.8460Epoch 00406: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6453 - acc: 0.8461    \n",
      "Epoch 408/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6222 - acc: 0.8536Epoch 00407: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6219 - acc: 0.8537    \n",
      "Epoch 409/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6674 - acc: 0.8506Epoch 00408: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6682 - acc: 0.8505    \n",
      "Epoch 410/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6853 - acc: 0.8451Epoch 00409: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6850 - acc: 0.8451    \n",
      "Epoch 411/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6079 - acc: 0.8560Epoch 00410: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.6072 - acc: 0.8561    \n",
      "Epoch 412/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5680 - acc: 0.8636Epoch 00411: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.5685 - acc: 0.8636    \n",
      "Epoch 413/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5637 - acc: 0.8649Epoch 00412: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5635 - acc: 0.8649    \n",
      "Epoch 414/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.8759Epoch 00413: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5099 - acc: 0.8759    \n",
      "Epoch 415/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.8765Epoch 00414: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5071 - acc: 0.8764    \n",
      "Epoch 416/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.8703Epoch 00415: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5353 - acc: 0.8703    \n",
      "Epoch 417/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8808Epoch 00416: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4898 - acc: 0.8807    \n",
      "Epoch 418/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.8813Epoch 00417: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4861 - acc: 0.8813    \n",
      "Epoch 419/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8846Epoch 00418: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4673 - acc: 0.8847    \n",
      "Epoch 420/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4349 - acc: 0.8921Epoch 00419: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4350 - acc: 0.8921    \n",
      "Epoch 421/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4296 - acc: 0.8942Epoch 00420: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4295 - acc: 0.8942    \n",
      "Epoch 422/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.8964Epoch 00421: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4280 - acc: 0.8959    \n",
      "Epoch 423/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.6549 - acc: 0.8557Epoch 00422: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.6540 - acc: 0.8558    \n",
      "Epoch 424/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5517 - acc: 0.8667Epoch 00423: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5513 - acc: 0.8668    \n",
      "Epoch 425/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5232 - acc: 0.8723Epoch 00424: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5231 - acc: 0.8723    \n",
      "Epoch 426/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4999 - acc: 0.8783Epoch 00425: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5001 - acc: 0.8783    \n",
      "Epoch 427/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4798 - acc: 0.8826Epoch 00426: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4796 - acc: 0.8826    \n",
      "Epoch 428/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8869Epoch 00427: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4637 - acc: 0.8868    \n",
      "Epoch 429/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8881Epoch 00428: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4615 - acc: 0.8881    \n",
      "Epoch 430/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4581 - acc: 0.8902Epoch 00429: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4577 - acc: 0.8902    \n",
      "Epoch 431/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4340 - acc: 0.8955Epoch 00430: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4340 - acc: 0.8955    \n",
      "Epoch 432/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8985Epoch 00431: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4229 - acc: 0.8985    \n",
      "Epoch 433/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4124 - acc: 0.9011Epoch 00432: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4123 - acc: 0.9011    \n",
      "Epoch 434/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4017 - acc: 0.9038Epoch 00433: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4018 - acc: 0.9038    \n",
      "Epoch 435/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3964 - acc: 0.9054Epoch 00434: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3963 - acc: 0.9054    \n",
      "Epoch 436/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.9054Epoch 00435: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3985 - acc: 0.9054    \n",
      "Epoch 437/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.9046Epoch 00436: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4062 - acc: 0.9046    \n",
      "Epoch 438/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.9034Epoch 00437: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4109 - acc: 0.9034    \n",
      "Epoch 439/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.9051Epoch 00438: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4011 - acc: 0.9052    \n",
      "Epoch 440/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.9035Epoch 00439: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4125 - acc: 0.9036    \n",
      "Epoch 441/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.9036Epoch 00440: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4135 - acc: 0.9037    \n",
      "Epoch 442/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4019 - acc: 0.9061Epoch 00441: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4025 - acc: 0.9060    \n",
      "Epoch 443/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.9038Epoch 00442: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4121 - acc: 0.9039    \n",
      "Epoch 444/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.9070Epoch 00443: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3961 - acc: 0.9070    \n",
      "Epoch 445/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.9081Epoch 00444: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3897 - acc: 0.9080    \n",
      "Epoch 446/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.9076Epoch 00445: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3954 - acc: 0.9076    \n",
      "Epoch 447/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.9115Epoch 00446: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3795 - acc: 0.9116    \n",
      "Epoch 448/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.9141Epoch 00447: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3689 - acc: 0.9141    \n",
      "Epoch 449/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3651 - acc: 0.9151Epoch 00448: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3651 - acc: 0.9151    \n",
      "Epoch 450/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.9172Epoch 00449: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3579 - acc: 0.9172    \n",
      "Epoch 451/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.9188Epoch 00450: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3515 - acc: 0.9188    \n",
      "Epoch 452/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.9209Epoch 00451: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.3447 - acc: 0.9210    \n",
      "Epoch 453/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3393 - acc: 0.9225Epoch 00452: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3392 - acc: 0.9225    \n",
      "Epoch 454/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.9234Epoch 00453: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3365 - acc: 0.9235    \n",
      "Epoch 455/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.9245Epoch 00454: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3340 - acc: 0.9245    \n",
      "Epoch 456/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.9258Epoch 00455: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3297 - acc: 0.9258    \n",
      "Epoch 457/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.9253Epoch 00456: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3329 - acc: 0.9253    \n",
      "Epoch 458/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.9265Epoch 00457: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3278 - acc: 0.9266    \n",
      "Epoch 459/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.9267Epoch 00458: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3272 - acc: 0.9267    \n",
      "Epoch 460/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3225 - acc: 0.9282Epoch 00459: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3225 - acc: 0.9282    \n",
      "Epoch 461/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.9295Epoch 00460: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3181 - acc: 0.9295    \n",
      "Epoch 462/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.9304Epoch 00461: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3153 - acc: 0.9303    \n",
      "Epoch 463/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3143 - acc: 0.9307Epoch 00462: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3144 - acc: 0.9307    \n",
      "Epoch 464/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.9316Epoch 00463: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3113 - acc: 0.9316    \n",
      "Epoch 465/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.9323Epoch 00464: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3083 - acc: 0.9322    \n",
      "Epoch 466/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.9309Epoch 00465: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3136 - acc: 0.9309    \n",
      "Epoch 467/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3142 - acc: 0.9305Epoch 00466: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3146 - acc: 0.9304    \n",
      "Epoch 468/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.9225Epoch 00467: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3393 - acc: 0.9226    \n",
      "Epoch 469/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3197 - acc: 0.9281Epoch 00468: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3195 - acc: 0.9281    \n",
      "Epoch 470/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3126 - acc: 0.9308Epoch 00469: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3126 - acc: 0.9307    \n",
      "Epoch 471/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9317Epoch 00470: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3097 - acc: 0.9317    \n",
      "Epoch 472/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9327Epoch 00471: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3063 - acc: 0.9327    \n",
      "Epoch 473/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.9340Epoch 00472: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3023 - acc: 0.9339    \n",
      "Epoch 474/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2991 - acc: 0.9350Epoch 00473: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2992 - acc: 0.9350    \n",
      "Epoch 475/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9348Epoch 00474: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3010 - acc: 0.9348    \n",
      "Epoch 476/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.9319Epoch 00475: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3186 - acc: 0.9317    \n",
      "Epoch 477/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3704 - acc: 0.9181Epoch 00476: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3702 - acc: 0.9182    \n",
      "Epoch 478/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3339 - acc: 0.9265Epoch 00477: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3336 - acc: 0.9265    \n",
      "Epoch 479/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.9294Epoch 00478: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3225 - acc: 0.9295    \n",
      "Epoch 480/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3136 - acc: 0.9317Epoch 00479: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3135 - acc: 0.9317    \n",
      "Epoch 481/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9337Epoch 00480: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3055 - acc: 0.9338    \n",
      "Epoch 482/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9344Epoch 00481: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3043 - acc: 0.9344    \n",
      "Epoch 483/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9359Epoch 00482: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2977 - acc: 0.9359    \n",
      "Epoch 484/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.9195Epoch 00483: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3728 - acc: 0.9195    \n",
      "Epoch 485/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.9261Epoch 00484: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3408 - acc: 0.9261    \n",
      "Epoch 486/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.9301Epoch 00485: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3218 - acc: 0.9301    \n",
      "Epoch 487/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3115 - acc: 0.9326Epoch 00486: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3115 - acc: 0.9325    \n",
      "Epoch 488/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.9291Epoch 00487: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3233 - acc: 0.9292    \n",
      "Epoch 489/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.9320Epoch 00488: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3130 - acc: 0.9320    \n",
      "Epoch 490/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9334Epoch 00489: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3069 - acc: 0.9334    \n",
      "Epoch 491/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.9319Epoch 00490: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3168 - acc: 0.9319    \n",
      "Epoch 492/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.9310Epoch 00491: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3194 - acc: 0.9311    \n",
      "Epoch 493/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3089 - acc: 0.9332Epoch 00492: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3089 - acc: 0.9333    \n",
      "Epoch 494/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9354Epoch 00493: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2999 - acc: 0.9354    \n",
      "Epoch 495/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.9301Epoch 00494: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3164 - acc: 0.9301    \n",
      "Epoch 496/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3136 - acc: 0.9309Epoch 00495: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3133 - acc: 0.9309    \n",
      "Epoch 497/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.9330Epoch 00496: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3059 - acc: 0.9329    \n",
      "Epoch 498/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3359 - acc: 0.9263Epoch 00497: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3359 - acc: 0.9263    \n",
      "Epoch 499/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.9286Epoch 00498: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3264 - acc: 0.9286    \n",
      "Epoch 500/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.9291Epoch 00499: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3217 - acc: 0.9292    \n",
      "Epoch 501/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3089 - acc: 0.9330Epoch 00500: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3089 - acc: 0.9330    \n",
      "Epoch 502/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3018 - acc: 0.9356Epoch 00501: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3019 - acc: 0.9356    \n",
      "Epoch 503/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2948 - acc: 0.9381Epoch 00502: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2949 - acc: 0.9381    \n",
      "Epoch 504/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9397Epoch 00503: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2884 - acc: 0.9397    \n",
      "Epoch 505/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9377Epoch 00504: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2989 - acc: 0.9376    \n",
      "Epoch 506/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.9343Epoch 00505: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3136 - acc: 0.9343    \n",
      "Epoch 507/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.9346Epoch 00506: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3124 - acc: 0.9346    \n",
      "Epoch 508/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3003 - acc: 0.9375Epoch 00507: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3004 - acc: 0.9375    \n",
      "Epoch 509/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.9401Epoch 00508: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2905 - acc: 0.9401    \n",
      "Epoch 510/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9410Epoch 00509: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2867 - acc: 0.9409    \n",
      "Epoch 511/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9417Epoch 00510: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2836 - acc: 0.9417    \n",
      "Epoch 512/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9427Epoch 00511: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2794 - acc: 0.9426    \n",
      "Epoch 513/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9424Epoch 00512: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2819 - acc: 0.9424    \n",
      "Epoch 514/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2769 - acc: 0.9433Epoch 00513: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2770 - acc: 0.9433    \n",
      "Epoch 515/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2754 - acc: 0.9432Epoch 00514: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2755 - acc: 0.9432    \n",
      "Epoch 516/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9444Epoch 00515: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2720 - acc: 0.9445    \n",
      "Epoch 517/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9449Epoch 00516: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2701 - acc: 0.9449    \n",
      "Epoch 518/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9444Epoch 00517: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2726 - acc: 0.9444    \n",
      "Epoch 519/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.9347Epoch 00518: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3106 - acc: 0.9347    \n",
      "Epoch 520/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.9366Epoch 00519: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3063 - acc: 0.9366    \n",
      "Epoch 521/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9405Epoch 00520: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2890 - acc: 0.9405    \n",
      "Epoch 522/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9424Epoch 00521: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2809 - acc: 0.9424    \n",
      "Epoch 523/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9417Epoch 00522: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2836 - acc: 0.9417    \n",
      "Epoch 524/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9425Epoch 00523: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2814 - acc: 0.9425    \n",
      "Epoch 525/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9441Epoch 00524: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2749 - acc: 0.9441    \n",
      "Epoch 526/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.9195Epoch 00525: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4121 - acc: 0.9193    \n",
      "Epoch 527/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.9122Epoch 00526: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4251 - acc: 0.9122    \n",
      "Epoch 528/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.9239Epoch 00527: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3688 - acc: 0.9239    \n",
      "Epoch 529/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.9296Epoch 00528: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3413 - acc: 0.9296    \n",
      "Epoch 530/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.9242Epoch 00529: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3569 - acc: 0.9241    \n",
      "Epoch 531/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.9145Epoch 00530: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3912 - acc: 0.9144    \n",
      "Epoch 532/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3852 - acc: 0.9155Epoch 00531: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3850 - acc: 0.9156    \n",
      "Epoch 533/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3469 - acc: 0.9247Epoch 00532: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3469 - acc: 0.9247    \n",
      "Epoch 534/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.9301Epoch 00533: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3252 - acc: 0.9301    \n",
      "Epoch 535/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3098 - acc: 0.9336Epoch 00534: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3099 - acc: 0.9336    \n",
      "Epoch 536/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.9354Epoch 00535: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3033 - acc: 0.9354    \n",
      "Epoch 537/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.9376Epoch 00536: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2942 - acc: 0.9376    \n",
      "Epoch 538/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9394Epoch 00537: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2880 - acc: 0.9395    \n",
      "Epoch 539/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2995 - acc: 0.9376Epoch 00538: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2998 - acc: 0.9376    \n",
      "Epoch 540/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3384 - acc: 0.9292Epoch 00539: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3388 - acc: 0.9291    \n",
      "Epoch 541/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.9281Epoch 00540: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3464 - acc: 0.9281    \n",
      "Epoch 542/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.9330Epoch 00541: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3255 - acc: 0.9331    \n",
      "Epoch 543/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.9346Epoch 00542: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3177 - acc: 0.9346    \n",
      "Epoch 544/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9374Epoch 00543: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3063 - acc: 0.9374    \n",
      "Epoch 545/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9399Epoch 00544: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2972 - acc: 0.9399    \n",
      "Epoch 546/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9378Epoch 00545: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3042 - acc: 0.9378    \n",
      "Epoch 547/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.9370Epoch 00546: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3094 - acc: 0.9370    \n",
      "Epoch 548/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.9367Epoch 00547: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3087 - acc: 0.9367    \n",
      "Epoch 549/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2968 - acc: 0.9401Epoch 00548: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2966 - acc: 0.9402    \n",
      "Epoch 550/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.9425Epoch 00549: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2896 - acc: 0.9425    \n",
      "Epoch 551/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9440Epoch 00550: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2848 - acc: 0.9440    \n",
      "Epoch 552/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.9450Epoch 00551: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2785 - acc: 0.9450    \n",
      "Epoch 553/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2781 - acc: 0.9438Epoch 00552: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2782 - acc: 0.9438    \n",
      "Epoch 554/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9436Epoch 00553: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2800 - acc: 0.9436    \n",
      "Epoch 555/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9455Epoch 00554: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2727 - acc: 0.9455    \n",
      "Epoch 556/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2701 - acc: 0.9457Epoch 00555: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2701 - acc: 0.9458    \n",
      "Epoch 557/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9431Epoch 00556: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2774 - acc: 0.9431    \n",
      "Epoch 558/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2761 - acc: 0.9425Epoch 00557: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2761 - acc: 0.9425    \n",
      "Epoch 559/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2754 - acc: 0.9432Epoch 00558: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2755 - acc: 0.9432    \n",
      "Epoch 560/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9442Epoch 00559: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2728 - acc: 0.9442    \n",
      "Epoch 561/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9447Epoch 00560: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2722 - acc: 0.9446    \n",
      "Epoch 562/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9456Epoch 00561: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2692 - acc: 0.9456    \n",
      "Epoch 563/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9468Epoch 00562: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2655 - acc: 0.9468    \n",
      "Epoch 564/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9474Epoch 00563: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2622 - acc: 0.9474    \n",
      "Epoch 565/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9480Epoch 00564: acc improved from 0.94792 to 0.94802, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.2602 - acc: 0.9480    \n",
      "Epoch 566/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.9474Epoch 00565: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2634 - acc: 0.9474    \n",
      "Epoch 567/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9465Epoch 00566: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2677 - acc: 0.9465    \n",
      "Epoch 568/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.9474Epoch 00567: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2635 - acc: 0.9474    \n",
      "Epoch 569/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9480Epoch 00568: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2610 - acc: 0.9480    \n",
      "Epoch 570/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9479Epoch 00569: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2625 - acc: 0.9479    \n",
      "Epoch 571/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3178 - acc: 0.9360Epoch 00570: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3180 - acc: 0.9360    \n",
      "Epoch 572/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9389Epoch 00571: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3013 - acc: 0.9389    \n",
      "Epoch 573/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9421Epoch 00572: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2866 - acc: 0.9421    \n",
      "Epoch 574/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.9305Epoch 00573: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3509 - acc: 0.9301    \n",
      "Epoch 575/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.9088Epoch 00574: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4270 - acc: 0.9088    \n",
      "Epoch 576/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.9234Epoch 00575: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3615 - acc: 0.9235    \n",
      "Epoch 577/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.9315Epoch 00576: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3349 - acc: 0.9315    \n",
      "Epoch 578/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3204 - acc: 0.9348Epoch 00577: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3202 - acc: 0.9349    \n",
      "Epoch 579/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.9369Epoch 00578: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3109 - acc: 0.9369    \n",
      "Epoch 580/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3119 - acc: 0.9361Epoch 00579: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3125 - acc: 0.9360    \n",
      "Epoch 581/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.9343Epoch 00580: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3266 - acc: 0.9344    \n",
      "Epoch 582/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.9386Epoch 00581: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3076 - acc: 0.9386    \n",
      "Epoch 583/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9397Epoch 00582: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3012 - acc: 0.9397    \n",
      "Epoch 584/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.9399Epoch 00583: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3000 - acc: 0.9398    \n",
      "Epoch 585/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.9411Epoch 00584: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2955 - acc: 0.9411    \n",
      "Epoch 586/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9428Epoch 00585: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2878 - acc: 0.9428    \n",
      "Epoch 587/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2794 - acc: 0.9445Epoch 00586: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2795 - acc: 0.9445    \n",
      "Epoch 588/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9451Epoch 00587: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2771 - acc: 0.9451    \n",
      "Epoch 589/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.9452Epoch 00588: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2768 - acc: 0.9452    \n",
      "Epoch 590/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2730 - acc: 0.9460Epoch 00589: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2731 - acc: 0.9459    \n",
      "Epoch 591/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9425Epoch 00590: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2805 - acc: 0.9425    \n",
      "Epoch 592/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9422Epoch 00591: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2801 - acc: 0.9422    \n",
      "Epoch 593/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.9430Epoch 00592: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2797 - acc: 0.9430    \n",
      "Epoch 594/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.9452Epoch 00593: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2762 - acc: 0.9452    \n",
      "Epoch 595/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.9172Epoch 00594: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4145 - acc: 0.9166    \n",
      "Epoch 596/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5471 - acc: 0.8831Epoch 00595: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5466 - acc: 0.8832    \n",
      "Epoch 597/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5987 - acc: 0.8714Epoch 00596: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.6007 - acc: 0.8708    \n",
      "Epoch 598/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.7145 - acc: 0.8447Epoch 00597: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.7132 - acc: 0.8449    \n",
      "Epoch 599/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.8679Epoch 00598: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5769 - acc: 0.8679    \n",
      "Epoch 600/10000\n",
      "136000/137861 [============================>.] - ETA: 1s - loss: 0.5042 - acc: 0.8878Epoch 00599: acc did not improve\n",
      "137861/137861 [==============================] - 77s - loss: 0.5037 - acc: 0.8879    \n",
      "Epoch 601/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.9031Epoch 00600: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4472 - acc: 0.9031    \n",
      "Epoch 602/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.9117Epoch 00601: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4048 - acc: 0.9118    \n",
      "Epoch 603/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.9178Epoch 00602: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3793 - acc: 0.9178    \n",
      "Epoch 604/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.9213Epoch 00603: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3646 - acc: 0.9214    \n",
      "Epoch 605/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.9239Epoch 00604: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3562 - acc: 0.9239    \n",
      "Epoch 606/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.9267Epoch 00605: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3443 - acc: 0.9267    \n",
      "Epoch 607/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3340 - acc: 0.9290Epoch 00606: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3339 - acc: 0.9290    \n",
      "Epoch 608/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.9286Epoch 00607: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3360 - acc: 0.9285    \n",
      "Epoch 609/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.9270Epoch 00608: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3432 - acc: 0.9270    \n",
      "Epoch 610/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3393 - acc: 0.9282Epoch 00609: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3397 - acc: 0.9281    \n",
      "Epoch 611/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.9248Epoch 00610: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3617 - acc: 0.9248    \n",
      "Epoch 612/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.9292Epoch 00611: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3400 - acc: 0.9291    \n",
      "Epoch 613/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3306 - acc: 0.9317Epoch 00612: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3305 - acc: 0.9317    \n",
      "Epoch 614/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.9351Epoch 00613: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3180 - acc: 0.9351    \n",
      "Epoch 615/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.9366Epoch 00614: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3116 - acc: 0.9366    \n",
      "Epoch 616/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.9366Epoch 00615: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3142 - acc: 0.9366    \n",
      "Epoch 617/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3052 - acc: 0.9382Epoch 00616: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3052 - acc: 0.9383    \n",
      "Epoch 618/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.9396Epoch 00617: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2988 - acc: 0.9396    \n",
      "Epoch 619/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2974 - acc: 0.9402Epoch 00618: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2974 - acc: 0.9402    \n",
      "Epoch 620/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2938 - acc: 0.9412Epoch 00619: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2940 - acc: 0.9412    \n",
      "Epoch 621/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9415Epoch 00620: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2932 - acc: 0.9415    \n",
      "Epoch 622/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9427Epoch 00621: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2883 - acc: 0.9427    \n",
      "Epoch 623/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9437Epoch 00622: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2832 - acc: 0.9437    \n",
      "Epoch 624/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9438Epoch 00623: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2842 - acc: 0.9438    \n",
      "Epoch 625/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9434Epoch 00624: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2868 - acc: 0.9433    \n",
      "Epoch 626/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2942 - acc: 0.9419Epoch 00625: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2943 - acc: 0.9419    \n",
      "Epoch 627/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9402Epoch 00626: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3068 - acc: 0.9401    \n",
      "Epoch 628/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.9364Epoch 00627: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3237 - acc: 0.9364    \n",
      "Epoch 629/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.9350Epoch 00628: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3327 - acc: 0.9350    \n",
      "Epoch 630/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3327 - acc: 0.9353Epoch 00629: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3326 - acc: 0.9353    \n",
      "Epoch 631/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.9377Epoch 00630: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3195 - acc: 0.9377    \n",
      "Epoch 632/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3106 - acc: 0.9392Epoch 00631: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3106 - acc: 0.9392    \n",
      "Epoch 633/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3098 - acc: 0.9388Epoch 00632: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3099 - acc: 0.9388    \n",
      "Epoch 634/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3049 - acc: 0.9400Epoch 00633: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3048 - acc: 0.9400    \n",
      "Epoch 635/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9408Epoch 00634: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3013 - acc: 0.9408    \n",
      "Epoch 636/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9419Epoch 00635: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2970 - acc: 0.9419    \n",
      "Epoch 637/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.9425Epoch 00636: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2958 - acc: 0.9425    \n",
      "Epoch 638/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.9437Epoch 00637: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2920 - acc: 0.9436    \n",
      "Epoch 639/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9444Epoch 00638: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2890 - acc: 0.9444    \n",
      "Epoch 640/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9428Epoch 00639: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2975 - acc: 0.9427    \n",
      "Epoch 641/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.9441Epoch 00640: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2914 - acc: 0.9440    \n",
      "Epoch 642/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9450Epoch 00641: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2879 - acc: 0.9450    \n",
      "Epoch 643/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.9432Epoch 00642: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2990 - acc: 0.9432    \n",
      "Epoch 644/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.9420Epoch 00643: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3052 - acc: 0.9420    \n",
      "Epoch 645/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9424Epoch 00644: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3024 - acc: 0.9424    \n",
      "Epoch 646/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.9431Epoch 00645: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2992 - acc: 0.9431    \n",
      "Epoch 647/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3020 - acc: 0.9426Epoch 00646: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3019 - acc: 0.9426    \n",
      "Epoch 648/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3015 - acc: 0.9427Epoch 00647: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3015 - acc: 0.9427    \n",
      "Epoch 649/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.9435Epoch 00648: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2972 - acc: 0.9435    \n",
      "Epoch 650/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2959 - acc: 0.9437Epoch 00649: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2959 - acc: 0.9437    \n",
      "Epoch 651/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9438Epoch 00650: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2953 - acc: 0.9438    \n",
      "Epoch 652/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9448Epoch 00651: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2907 - acc: 0.9448    \n",
      "Epoch 653/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.9455Epoch 00652: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2878 - acc: 0.9455    \n",
      "Epoch 654/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9454Epoch 00653: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2887 - acc: 0.9454    \n",
      "Epoch 655/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.9454Epoch 00654: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2896 - acc: 0.9454    \n",
      "Epoch 656/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9454Epoch 00655: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2898 - acc: 0.9454    \n",
      "Epoch 657/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.9449Epoch 00656: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2915 - acc: 0.9449    \n",
      "Epoch 658/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9459Epoch 00657: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2865 - acc: 0.9459    \n",
      "Epoch 659/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.9450Epoch 00658: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2906 - acc: 0.9450    \n",
      "Epoch 660/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9423Epoch 00659: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3012 - acc: 0.9422    \n",
      "Epoch 661/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.9425Epoch 00660: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2965 - acc: 0.9425    \n",
      "Epoch 662/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.9431Epoch 00661: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2930 - acc: 0.9431    \n",
      "Epoch 663/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9441Epoch 00662: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2875 - acc: 0.9441    \n",
      "Epoch 664/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9451Epoch 00663: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2838 - acc: 0.9450    \n",
      "Epoch 665/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2837 - acc: 0.9451Epoch 00664: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2838 - acc: 0.9451    \n",
      "Epoch 666/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9445Epoch 00665: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2887 - acc: 0.9445    \n",
      "Epoch 667/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.9452Epoch 00666: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2843 - acc: 0.9452    \n",
      "Epoch 668/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9457Epoch 00667: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2812 - acc: 0.9458    \n",
      "Epoch 669/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2809 - acc: 0.9458Epoch 00668: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2807 - acc: 0.9458    \n",
      "Epoch 670/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.9431Epoch 00669: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2958 - acc: 0.9430    \n",
      "Epoch 671/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.9397Epoch 00670: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3115 - acc: 0.9396    \n",
      "Epoch 672/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.9385Epoch 00671: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3174 - acc: 0.9384    \n",
      "Epoch 673/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.9401Epoch 00672: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3126 - acc: 0.9401    \n",
      "Epoch 674/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9404Epoch 00673: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3127 - acc: 0.9403    \n",
      "Epoch 675/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.9383Epoch 00674: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3194 - acc: 0.9383    \n",
      "Epoch 676/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3083 - acc: 0.9406Epoch 00675: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3082 - acc: 0.9406    \n",
      "Epoch 677/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.9422Epoch 00676: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3032 - acc: 0.9422    \n",
      "Epoch 678/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.9346Epoch 00677: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3409 - acc: 0.9346    \n",
      "Epoch 679/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.9378Epoch 00678: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3248 - acc: 0.9379    \n",
      "Epoch 680/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3428 - acc: 0.9328Epoch 00679: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3431 - acc: 0.9328    \n",
      "Epoch 681/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.9311Epoch 00680: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3492 - acc: 0.9311    \n",
      "Epoch 682/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.9289Epoch 00681: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3590 - acc: 0.9288    \n",
      "Epoch 683/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.9296Epoch 00682: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3598 - acc: 0.9297    \n",
      "Epoch 684/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.9369Epoch 00683: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3268 - acc: 0.9369    \n",
      "Epoch 685/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9401Epoch 00684: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3106 - acc: 0.9401    \n",
      "Epoch 686/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.9418Epoch 00685: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3033 - acc: 0.9418    \n",
      "Epoch 687/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9414Epoch 00686: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3054 - acc: 0.9414    \n",
      "Epoch 688/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9434Epoch 00687: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2971 - acc: 0.9434    \n",
      "Epoch 689/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.9039Epoch 00688: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4335 - acc: 0.9040    \n",
      "Epoch 690/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.9175Epoch 00689: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3838 - acc: 0.9176    \n",
      "Epoch 691/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3544 - acc: 0.9269Epoch 00690: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3548 - acc: 0.9268    \n",
      "Epoch 692/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.9296Epoch 00691: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3464 - acc: 0.9296    \n",
      "Epoch 693/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3320 - acc: 0.9330Epoch 00692: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3322 - acc: 0.9330    \n",
      "Epoch 694/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3273 - acc: 0.9342Epoch 00693: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3279 - acc: 0.9341    \n",
      "Epoch 695/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.9269Epoch 00694: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3690 - acc: 0.9269    \n",
      "Epoch 696/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.9321Epoch 00695: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3407 - acc: 0.9322    \n",
      "Epoch 697/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.9331Epoch 00696: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3330 - acc: 0.9330    \n",
      "Epoch 698/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3170 - acc: 0.9361Epoch 00697: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3174 - acc: 0.9361    \n",
      "Epoch 699/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3229 - acc: 0.9356Epoch 00698: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3228 - acc: 0.9356    \n",
      "Epoch 700/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9376Epoch 00699: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3101 - acc: 0.9376    \n",
      "Epoch 701/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9286Epoch 00700: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3397 - acc: 0.9284    \n",
      "Epoch 702/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.9169Epoch 00701: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3801 - acc: 0.9169    \n",
      "Epoch 703/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3561 - acc: 0.9235Epoch 00702: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3561 - acc: 0.9235    \n",
      "Epoch 704/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.9273Epoch 00703: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3375 - acc: 0.9274    \n",
      "Epoch 705/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3182 - acc: 0.9325Epoch 00704: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3181 - acc: 0.9325    \n",
      "Epoch 706/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3382 - acc: 0.9305Epoch 00705: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3383 - acc: 0.9305    \n",
      "Epoch 707/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.9297Epoch 00706: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3397 - acc: 0.9297    \n",
      "Epoch 708/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9348Epoch 00707: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3163 - acc: 0.9348    \n",
      "Epoch 709/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.9328Epoch 00708: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3261 - acc: 0.9328    \n",
      "Epoch 710/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9352Epoch 00709: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3173 - acc: 0.9352    \n",
      "Epoch 711/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3034 - acc: 0.9384Epoch 00710: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3035 - acc: 0.9384    \n",
      "Epoch 712/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3650 - acc: 0.9256Epoch 00711: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3647 - acc: 0.9256    \n",
      "Epoch 713/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.9296Epoch 00712: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3432 - acc: 0.9297    \n",
      "Epoch 714/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.9241Epoch 00713: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3729 - acc: 0.9240    \n",
      "Epoch 715/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.9242Epoch 00714: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3717 - acc: 0.9243    \n",
      "Epoch 716/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4005 - acc: 0.9195Epoch 00715: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4011 - acc: 0.9194    \n",
      "Epoch 717/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3868 - acc: 0.9234Epoch 00716: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3863 - acc: 0.9235    \n",
      "Epoch 718/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.9298Epoch 00717: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3528 - acc: 0.9298    \n",
      "Epoch 719/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.9342Epoch 00718: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3295 - acc: 0.9341    \n",
      "Epoch 720/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3579 - acc: 0.9279Epoch 00719: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3581 - acc: 0.9279    \n",
      "Epoch 721/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3577 - acc: 0.9283Epoch 00720: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3580 - acc: 0.9283    \n",
      "Epoch 722/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.9335Epoch 00721: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3336 - acc: 0.9335    \n",
      "Epoch 723/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.9303Epoch 00722: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3521 - acc: 0.9303    \n",
      "Epoch 724/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3450 - acc: 0.9317Epoch 00723: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3449 - acc: 0.9318    \n",
      "Epoch 725/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.9358Epoch 00724: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3240 - acc: 0.9358    \n",
      "Epoch 726/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3166 - acc: 0.9367Epoch 00725: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3165 - acc: 0.9367    \n",
      "Epoch 727/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3128 - acc: 0.9373Epoch 00726: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3129 - acc: 0.9372    \n",
      "Epoch 728/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3096 - acc: 0.9370Epoch 00727: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3096 - acc: 0.9370    \n",
      "Epoch 729/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3005 - acc: 0.9399Epoch 00728: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3005 - acc: 0.9399    \n",
      "Epoch 730/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2938 - acc: 0.9423Epoch 00729: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2940 - acc: 0.9423    \n",
      "Epoch 731/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9438Epoch 00730: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2886 - acc: 0.9438    \n",
      "Epoch 732/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9405Epoch 00731: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3038 - acc: 0.9404    \n",
      "Epoch 733/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.9407Epoch 00732: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3064 - acc: 0.9406    \n",
      "Epoch 734/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.9358Epoch 00733: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3284 - acc: 0.9359    \n",
      "Epoch 735/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.9319Epoch 00734: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3514 - acc: 0.9318    \n",
      "Epoch 736/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.9333Epoch 00735: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3378 - acc: 0.9333    \n",
      "Epoch 737/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.9397Epoch 00736: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3093 - acc: 0.9397    \n",
      "Epoch 738/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9412Epoch 00737: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3026 - acc: 0.9412    \n",
      "Epoch 739/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3050 - acc: 0.9410Epoch 00738: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3054 - acc: 0.9409    \n",
      "Epoch 740/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.9359Epoch 00739: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3297 - acc: 0.9359    \n",
      "Epoch 741/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.9408Epoch 00740: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3031 - acc: 0.9409    \n",
      "Epoch 742/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2900 - acc: 0.9437Epoch 00741: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2901 - acc: 0.9437    \n",
      "Epoch 743/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9452Epoch 00742: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2837 - acc: 0.9452    \n",
      "Epoch 744/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2788 - acc: 0.9460Epoch 00743: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2787 - acc: 0.9460    \n",
      "Epoch 745/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9470Epoch 00744: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2748 - acc: 0.9470    \n",
      "Epoch 746/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2722 - acc: 0.9475Epoch 00745: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2722 - acc: 0.9475    \n",
      "Epoch 747/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9483Epoch 00746: acc improved from 0.94802 to 0.94829, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2688 - acc: 0.9483    \n",
      "Epoch 748/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9486Epoch 00747: acc improved from 0.94829 to 0.94865, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2677 - acc: 0.9487    \n",
      "Epoch 749/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9483Epoch 00748: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2694 - acc: 0.9482    \n",
      "Epoch 750/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.9424Epoch 00749: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2912 - acc: 0.9424    \n",
      "Epoch 751/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2809 - acc: 0.9456Epoch 00750: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2807 - acc: 0.9456    \n",
      "Epoch 752/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2732 - acc: 0.9475Epoch 00751: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2731 - acc: 0.9475    \n",
      "Epoch 753/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9489Epoch 00752: acc improved from 0.94865 to 0.94892, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2676 - acc: 0.9489    \n",
      "Epoch 754/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.9436Epoch 00753: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2931 - acc: 0.9436    \n",
      "Epoch 755/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9427Epoch 00754: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2969 - acc: 0.9427    \n",
      "Epoch 756/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.9413Epoch 00755: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2994 - acc: 0.9413    \n",
      "Epoch 757/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.9415Epoch 00756: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 66s - loss: 0.2981 - acc: 0.9415    \n",
      "Epoch 758/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3419 - acc: 0.9306Epoch 00757: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3433 - acc: 0.9303    \n",
      "Epoch 759/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.9223Epoch 00758: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3798 - acc: 0.9223    \n",
      "Epoch 760/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.9210Epoch 00759: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3799 - acc: 0.9210    \n",
      "Epoch 761/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.9197Epoch 00760: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3897 - acc: 0.9197    \n",
      "Epoch 762/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.8958Epoch 00761: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5067 - acc: 0.8953    \n",
      "Epoch 763/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.8892Epoch 00762: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5092 - acc: 0.8895    \n",
      "Epoch 764/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4115 - acc: 0.9142Epoch 00763: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4115 - acc: 0.9142    \n",
      "Epoch 765/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.9212Epoch 00764: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3805 - acc: 0.9212    \n",
      "Epoch 766/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.9263Epoch 00765: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3606 - acc: 0.9262    \n",
      "Epoch 767/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.9215Epoch 00766: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3822 - acc: 0.9215    \n",
      "Epoch 768/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3527 - acc: 0.9280Epoch 00767: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3527 - acc: 0.9281    \n",
      "Epoch 769/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.9314Epoch 00768: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3398 - acc: 0.9314    \n",
      "Epoch 770/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.9330Epoch 00769: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3348 - acc: 0.9328    \n",
      "Epoch 771/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.9283Epoch 00770: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3534 - acc: 0.9283    \n",
      "Epoch 772/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.9342Epoch 00771: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3282 - acc: 0.9342    \n",
      "Epoch 773/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3201 - acc: 0.9355Epoch 00772: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3202 - acc: 0.9355    \n",
      "Epoch 774/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3232 - acc: 0.9349Epoch 00773: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3236 - acc: 0.9348    \n",
      "Epoch 775/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.9313Epoch 00774: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3357 - acc: 0.9313    \n",
      "Epoch 776/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.9349Epoch 00775: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3176 - acc: 0.9349    \n",
      "Epoch 777/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3182 - acc: 0.9351Epoch 00776: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3188 - acc: 0.9350    \n",
      "Epoch 778/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.9320Epoch 00777: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3367 - acc: 0.9319    \n",
      "Epoch 779/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.9359Epoch 00778: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3162 - acc: 0.9359    \n",
      "Epoch 780/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.9362Epoch 00779: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3156 - acc: 0.9362    \n",
      "Epoch 781/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.9338Epoch 00780: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3219 - acc: 0.9338    \n",
      "Epoch 782/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.9335Epoch 00781: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3216 - acc: 0.9336    \n",
      "Epoch 783/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.9368Epoch 00782: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3062 - acc: 0.9368    \n",
      "Epoch 784/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.9378Epoch 00783: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3023 - acc: 0.9378    \n",
      "Epoch 785/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9391Epoch 00784: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2968 - acc: 0.9391    \n",
      "Epoch 786/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9396Epoch 00785: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2953 - acc: 0.9396    \n",
      "Epoch 787/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9398Epoch 00786: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2933 - acc: 0.9398    \n",
      "Epoch 788/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9377Epoch 00787: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2997 - acc: 0.9376    \n",
      "Epoch 789/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2993 - acc: 0.9387Epoch 00788: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2992 - acc: 0.9387    \n",
      "Epoch 790/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9392Epoch 00789: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2976 - acc: 0.9392    \n",
      "Epoch 791/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9408Epoch 00790: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2887 - acc: 0.9408    \n",
      "Epoch 792/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.9422Epoch 00791: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2818 - acc: 0.9422    \n",
      "Epoch 793/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.9388Epoch 00792: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2962 - acc: 0.9388    \n",
      "Epoch 794/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9414Epoch 00793: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2883 - acc: 0.9414    \n",
      "Epoch 795/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9423Epoch 00794: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2860 - acc: 0.9423    \n",
      "Epoch 796/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9420Epoch 00795: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2876 - acc: 0.9420    \n",
      "Epoch 797/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2780 - acc: 0.9444Epoch 00796: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2780 - acc: 0.9444    \n",
      "Epoch 798/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2733 - acc: 0.9453Epoch 00797: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2731 - acc: 0.9454    \n",
      "Epoch 799/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9440Epoch 00798: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2820 - acc: 0.9440    \n",
      "Epoch 800/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.9411Epoch 00799: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2957 - acc: 0.9410    \n",
      "Epoch 801/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3140 - acc: 0.9373Epoch 00800: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3141 - acc: 0.9373    \n",
      "Epoch 802/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3042 - acc: 0.9397Epoch 00801: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3039 - acc: 0.9397    \n",
      "Epoch 803/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9409Epoch 00802: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2978 - acc: 0.9408    \n",
      "Epoch 804/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9410Epoch 00803: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2932 - acc: 0.9410    \n",
      "Epoch 805/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2868 - acc: 0.9422Epoch 00804: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2867 - acc: 0.9422    \n",
      "Epoch 806/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2938 - acc: 0.9411Epoch 00805: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2938 - acc: 0.9411    \n",
      "Epoch 807/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.9434Epoch 00806: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2863 - acc: 0.9434    \n",
      "Epoch 808/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9441Epoch 00807: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2843 - acc: 0.9441    \n",
      "Epoch 809/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2771 - acc: 0.9456Epoch 00808: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2769 - acc: 0.9457    \n",
      "Epoch 810/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9466Epoch 00809: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2714 - acc: 0.9466    \n",
      "Epoch 811/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9465Epoch 00810: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2714 - acc: 0.9465    \n",
      "Epoch 812/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9470Epoch 00811: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2689 - acc: 0.9470    \n",
      "Epoch 813/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2648 - acc: 0.9479Epoch 00812: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2648 - acc: 0.9479    \n",
      "Epoch 814/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.9469Epoch 00813: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2700 - acc: 0.9468    \n",
      "Epoch 815/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3186 - acc: 0.9380Epoch 00814: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3187 - acc: 0.9380    \n",
      "Epoch 816/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.9363Epoch 00815: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3247 - acc: 0.9362    \n",
      "Epoch 817/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9386Epoch 00816: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3108 - acc: 0.9387    \n",
      "Epoch 818/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.9298Epoch 00817: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3344 - acc: 0.9299    \n",
      "Epoch 819/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.9374Epoch 00818: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3193 - acc: 0.9374    \n",
      "Epoch 820/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3170 - acc: 0.9377Epoch 00819: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3169 - acc: 0.9377    \n",
      "Epoch 821/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.9393Epoch 00820: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3082 - acc: 0.9393    \n",
      "Epoch 822/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9424Epoch 00821: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2936 - acc: 0.9425    \n",
      "Epoch 823/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9440Epoch 00822: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2861 - acc: 0.9440    \n",
      "Epoch 824/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4354 - acc: 0.9121Epoch 00823: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4353 - acc: 0.9120    \n",
      "Epoch 825/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.9193Epoch 00824: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3828 - acc: 0.9193    \n",
      "Epoch 826/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.9265Epoch 00825: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3478 - acc: 0.9264    \n",
      "Epoch 827/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.9252Epoch 00826: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3574 - acc: 0.9252    \n",
      "Epoch 828/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3541 - acc: 0.9263Epoch 00827: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3543 - acc: 0.9263    \n",
      "Epoch 829/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.9291Epoch 00828: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3420 - acc: 0.9292    \n",
      "Epoch 830/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3223 - acc: 0.9332Epoch 00829: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3223 - acc: 0.9333    \n",
      "Epoch 831/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.8968Epoch 00830: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 65s - loss: 0.4970 - acc: 0.8969    \n",
      "Epoch 832/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.9095Epoch 00831: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4370 - acc: 0.9094    \n",
      "Epoch 833/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4217 - acc: 0.9110Epoch 00832: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4215 - acc: 0.9110    \n",
      "Epoch 834/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3781 - acc: 0.9201Epoch 00833: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3779 - acc: 0.9201    \n",
      "Epoch 835/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.9252Epoch 00834: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3570 - acc: 0.9253    \n",
      "Epoch 836/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4172 - acc: 0.9152Epoch 00835: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4176 - acc: 0.9151    \n",
      "Epoch 837/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4252 - acc: 0.9115Epoch 00836: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4254 - acc: 0.9114    \n",
      "Epoch 838/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4042 - acc: 0.9152Epoch 00837: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4039 - acc: 0.9153    \n",
      "Epoch 839/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3710 - acc: 0.9230Epoch 00838: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3710 - acc: 0.9230    \n",
      "Epoch 840/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.9267Epoch 00839: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3548 - acc: 0.9267    \n",
      "Epoch 841/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.9304Epoch 00840: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3406 - acc: 0.9304    \n",
      "Epoch 842/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3345 - acc: 0.9325Epoch 00841: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3343 - acc: 0.9326    \n",
      "Epoch 843/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3300 - acc: 0.9338Epoch 00842: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3298 - acc: 0.9339    \n",
      "Epoch 844/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.9360Epoch 00843: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3218 - acc: 0.9360    \n",
      "Epoch 845/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9357Epoch 00844: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3212 - acc: 0.9357    \n",
      "Epoch 846/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.9337Epoch 00845: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3280 - acc: 0.9337    \n",
      "Epoch 847/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.9322Epoch 00846: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3303 - acc: 0.9321    \n",
      "Epoch 848/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.9305Epoch 00847: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3415 - acc: 0.9305    \n",
      "Epoch 849/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3361 - acc: 0.9327Epoch 00848: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3362 - acc: 0.9327    \n",
      "Epoch 850/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9365Epoch 00849: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3200 - acc: 0.9365    \n",
      "Epoch 851/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3116 - acc: 0.9381Epoch 00850: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3117 - acc: 0.9380    \n",
      "Epoch 852/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.9392Epoch 00851: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3062 - acc: 0.9392    \n",
      "Epoch 853/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.9401Epoch 00852: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3019 - acc: 0.9401    \n",
      "Epoch 854/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9410Epoch 00853: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2974 - acc: 0.9410    \n",
      "Epoch 855/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.9379Epoch 00854: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3114 - acc: 0.9379    \n",
      "Epoch 856/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9395Epoch 00855: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3038 - acc: 0.9395    \n",
      "Epoch 857/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.9401Epoch 00856: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3024 - acc: 0.9400    \n",
      "Epoch 858/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.9258Epoch 00857: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3817 - acc: 0.9259    \n",
      "Epoch 859/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.9314Epoch 00858: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3507 - acc: 0.9314    \n",
      "Epoch 860/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.9360Epoch 00859: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3279 - acc: 0.9360    \n",
      "Epoch 861/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3182 - acc: 0.9387Epoch 00860: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3182 - acc: 0.9387    \n",
      "Epoch 862/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3303 - acc: 0.9370Epoch 00861: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3301 - acc: 0.9370    \n",
      "Epoch 863/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.9398Epoch 00862: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3158 - acc: 0.9398    \n",
      "Epoch 864/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3085 - acc: 0.9413Epoch 00863: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3086 - acc: 0.9412    \n",
      "Epoch 865/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3005 - acc: 0.9429Epoch 00864: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3006 - acc: 0.9429    \n",
      "Epoch 866/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2945 - acc: 0.9442Epoch 00865: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2945 - acc: 0.9441    \n",
      "Epoch 867/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9446Epoch 00866: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2926 - acc: 0.9446    \n",
      "Epoch 868/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9454Epoch 00867: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2887 - acc: 0.9454    \n",
      "Epoch 869/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9460Epoch 00868: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2846 - acc: 0.9461    \n",
      "Epoch 870/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9465Epoch 00869: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2834 - acc: 0.9465    \n",
      "Epoch 871/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.9459Epoch 00870: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2863 - acc: 0.9459    \n",
      "Epoch 872/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.9462Epoch 00871: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2848 - acc: 0.9461    \n",
      "Epoch 873/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9468Epoch 00872: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2814 - acc: 0.9468    \n",
      "Epoch 874/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.9473Epoch 00873: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2789 - acc: 0.9473    \n",
      "Epoch 875/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9477Epoch 00874: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2770 - acc: 0.9477    \n",
      "Epoch 876/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2767 - acc: 0.9477Epoch 00875: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2767 - acc: 0.9478    \n",
      "Epoch 877/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9469Epoch 00876: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2812 - acc: 0.9469    \n",
      "Epoch 878/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9472Epoch 00877: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2802 - acc: 0.9472    \n",
      "Epoch 879/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.9476Epoch 00878: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2787 - acc: 0.9476    \n",
      "Epoch 880/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2752 - acc: 0.9482Epoch 00879: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2752 - acc: 0.9482    \n",
      "Epoch 881/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.9483Epoch 00880: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2756 - acc: 0.9483    \n",
      "Epoch 882/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2722 - acc: 0.9488Epoch 00881: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2723 - acc: 0.9488    \n",
      "Epoch 883/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.9494Epoch 00882: acc improved from 0.94892 to 0.94941, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2700 - acc: 0.9494    \n",
      "Epoch 884/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9497Epoch 00883: acc improved from 0.94941 to 0.94969, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2687 - acc: 0.9497    \n",
      "Epoch 885/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.9488Epoch 00884: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2727 - acc: 0.9488    \n",
      "Epoch 886/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9481Epoch 00885: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2771 - acc: 0.9481    \n",
      "Epoch 887/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9479Epoch 00886: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2771 - acc: 0.9479    \n",
      "Epoch 888/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9489Epoch 00887: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2727 - acc: 0.9489    \n",
      "Epoch 889/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9488Epoch 00888: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2717 - acc: 0.9488    \n",
      "Epoch 890/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.9480Epoch 00889: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2752 - acc: 0.9480    \n",
      "Epoch 891/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9484Epoch 00890: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2752 - acc: 0.9483    \n",
      "Epoch 892/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9486Epoch 00891: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2735 - acc: 0.9486    \n",
      "Epoch 893/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2720 - acc: 0.9490Epoch 00892: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2718 - acc: 0.9490    \n",
      "Epoch 894/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.9481Epoch 00893: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2768 - acc: 0.9481    \n",
      "Epoch 895/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9491Epoch 00894: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2712 - acc: 0.9492    \n",
      "Epoch 896/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9498Epoch 00895: acc improved from 0.94969 to 0.94978, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2682 - acc: 0.9498    \n",
      "Epoch 897/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.9502Epoch 00896: acc improved from 0.94978 to 0.95018, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2661 - acc: 0.9502    \n",
      "Epoch 898/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9504Epoch 00897: acc improved from 0.95018 to 0.95042, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2653 - acc: 0.9504    \n",
      "Epoch 899/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.9492Epoch 00898: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2685 - acc: 0.9492    \n",
      "Epoch 900/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9498Epoch 00899: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2661 - acc: 0.9498    \n",
      "Epoch 901/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9498Epoch 00900: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2683 - acc: 0.9498    \n",
      "Epoch 902/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2701 - acc: 0.9494Epoch 00901: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2701 - acc: 0.9494    \n",
      "Epoch 903/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2670 - acc: 0.9500Epoch 00902: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2671 - acc: 0.9500    \n",
      "Epoch 904/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9506Epoch 00903: acc improved from 0.95042 to 0.95060, saving model to weights.model_final5.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 67s - loss: 0.2654 - acc: 0.9506    \n",
      "Epoch 905/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2658 - acc: 0.9507Epoch 00904: acc improved from 0.95060 to 0.95070, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2660 - acc: 0.9507    \n",
      "Epoch 906/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2672 - acc: 0.9508Epoch 00905: acc improved from 0.95070 to 0.95074, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2673 - acc: 0.9507    \n",
      "Epoch 907/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9512Epoch 00906: acc improved from 0.95074 to 0.95125, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 65s - loss: 0.2652 - acc: 0.9512    \n",
      "Epoch 908/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9502Epoch 00907: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2714 - acc: 0.9501    \n",
      "Epoch 909/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2780 - acc: 0.9485Epoch 00908: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2780 - acc: 0.9485    \n",
      "Epoch 910/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9484Epoch 00909: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2782 - acc: 0.9484    \n",
      "Epoch 911/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2720 - acc: 0.9498Epoch 00910: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2720 - acc: 0.9498    \n",
      "Epoch 912/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9491Epoch 00911: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2745 - acc: 0.9491    \n",
      "Epoch 913/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9485Epoch 00912: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2783 - acc: 0.9485    \n",
      "Epoch 914/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.9479Epoch 00913: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2817 - acc: 0.9479    \n",
      "Epoch 915/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9485Epoch 00914: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2797 - acc: 0.9485    \n",
      "Epoch 916/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2799 - acc: 0.9482Epoch 00915: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2801 - acc: 0.9482    \n",
      "Epoch 917/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9471Epoch 00916: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2852 - acc: 0.9471    \n",
      "Epoch 918/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9453Epoch 00917: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2910 - acc: 0.9454    \n",
      "Epoch 919/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9480Epoch 00918: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2799 - acc: 0.9481    \n",
      "Epoch 920/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.9487Epoch 00919: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2765 - acc: 0.9487    \n",
      "Epoch 921/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9484Epoch 00920: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2783 - acc: 0.9483    \n",
      "Epoch 922/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9478Epoch 00921: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2818 - acc: 0.9478    \n",
      "Epoch 923/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2780 - acc: 0.9486Epoch 00922: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2777 - acc: 0.9486    \n",
      "Epoch 924/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9491Epoch 00923: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2755 - acc: 0.9491    \n",
      "Epoch 925/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.9491Epoch 00924: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2756 - acc: 0.9491    \n",
      "Epoch 926/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9501Epoch 00925: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2711 - acc: 0.9501    \n",
      "Epoch 927/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9507Epoch 00926: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2683 - acc: 0.9507    \n",
      "Epoch 928/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2684 - acc: 0.9507Epoch 00927: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2685 - acc: 0.9507    \n",
      "Epoch 929/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9505Epoch 00928: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2686 - acc: 0.9505    \n",
      "Epoch 930/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9513Epoch 00929: acc improved from 0.95125 to 0.95128, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 66s - loss: 0.2655 - acc: 0.9513    \n",
      "Epoch 931/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9501Epoch 00930: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2718 - acc: 0.9501    \n",
      "Epoch 932/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2825 - acc: 0.9477Epoch 00931: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2825 - acc: 0.9477    \n",
      "Epoch 933/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9484Epoch 00932: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2791 - acc: 0.9484    \n",
      "Epoch 934/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.9473Epoch 00933: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2865 - acc: 0.9472    \n",
      "Epoch 935/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.9458Epoch 00934: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2921 - acc: 0.9458    \n",
      "Epoch 936/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.9469Epoch 00935: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2863 - acc: 0.9469    \n",
      "Epoch 937/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.9474Epoch 00936: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2844 - acc: 0.9474    \n",
      "Epoch 938/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9484Epoch 00937: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2794 - acc: 0.9484    \n",
      "Epoch 939/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9488Epoch 00938: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2783 - acc: 0.9488    \n",
      "Epoch 940/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.9490Epoch 00939: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2767 - acc: 0.9490    \n",
      "Epoch 941/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2764 - acc: 0.9491Epoch 00940: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2765 - acc: 0.9491    \n",
      "Epoch 942/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9494Epoch 00941: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2750 - acc: 0.9494    \n",
      "Epoch 943/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2724 - acc: 0.9498Epoch 00942: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2723 - acc: 0.9498    \n",
      "Epoch 944/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9490Epoch 00943: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2752 - acc: 0.9490    \n",
      "Epoch 945/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9473Epoch 00944: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2850 - acc: 0.9473    \n",
      "Epoch 946/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9457Epoch 00945: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2921 - acc: 0.9457    \n",
      "Epoch 947/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.9340Epoch 00946: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3404 - acc: 0.9339    \n",
      "Epoch 948/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.9360Epoch 00947: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3242 - acc: 0.9361    \n",
      "Epoch 949/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3070 - acc: 0.9399Epoch 00948: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3071 - acc: 0.9398    \n",
      "Epoch 950/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.9406Epoch 00949: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3030 - acc: 0.9407    \n",
      "Epoch 951/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.9422Epoch 00950: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2960 - acc: 0.9423    \n",
      "Epoch 952/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9413Epoch 00951: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3039 - acc: 0.9412    \n",
      "Epoch 953/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.9409Epoch 00952: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3058 - acc: 0.9409    \n",
      "Epoch 954/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.9429Epoch 00953: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2982 - acc: 0.9429    \n",
      "Epoch 955/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9440Epoch 00954: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2933 - acc: 0.9440    \n",
      "Epoch 956/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9449Epoch 00955: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2887 - acc: 0.9449    \n",
      "Epoch 957/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.9457Epoch 00956: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2852 - acc: 0.9457    \n",
      "Epoch 958/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9461Epoch 00957: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2829 - acc: 0.9461    \n",
      "Epoch 959/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9464Epoch 00958: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2814 - acc: 0.9464    \n",
      "Epoch 960/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9458Epoch 00959: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2842 - acc: 0.9458    \n",
      "Epoch 961/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.9404Epoch 00960: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3136 - acc: 0.9403    \n",
      "Epoch 962/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.9406Epoch 00961: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3113 - acc: 0.9406    \n",
      "Epoch 963/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3091 - acc: 0.9408Epoch 00962: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3105 - acc: 0.9405    \n",
      "Epoch 964/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4118 - acc: 0.9217Epoch 00963: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.4112 - acc: 0.9218    \n",
      "Epoch 965/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3584 - acc: 0.9310Epoch 00964: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3583 - acc: 0.9310    \n",
      "Epoch 966/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3376 - acc: 0.9352Epoch 00965: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3374 - acc: 0.9353    \n",
      "Epoch 967/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.9352Epoch 00966: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3363 - acc: 0.9352    \n",
      "Epoch 968/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.9378Epoch 00967: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3224 - acc: 0.9377    \n",
      "Epoch 969/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.9386Epoch 00968: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.3191 - acc: 0.9386    \n",
      "Epoch 970/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9407Epoch 00969: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3063 - acc: 0.9407    \n",
      "Epoch 971/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9416Epoch 00970: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3025 - acc: 0.9416    \n",
      "Epoch 972/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.9412Epoch 00971: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3051 - acc: 0.9412    \n",
      "Epoch 973/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9407Epoch 00972: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3092 - acc: 0.9406    \n",
      "Epoch 974/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9409Epoch 00973: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3048 - acc: 0.9409    \n",
      "Epoch 975/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.9400Epoch 00974: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3101 - acc: 0.9400    \n",
      "Epoch 976/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.9415Epoch 00975: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3024 - acc: 0.9415    \n",
      "Epoch 977/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9426Epoch 00976: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 67s - loss: 0.2968 - acc: 0.9425    \n",
      "Epoch 978/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9443Epoch 00977: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2886 - acc: 0.9443    \n",
      "Epoch 979/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9441Epoch 00978: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2896 - acc: 0.9441    \n",
      "Epoch 980/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9455Epoch 00979: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2825 - acc: 0.9455    \n",
      "Epoch 981/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2788 - acc: 0.9462Epoch 00980: acc did not improve\n",
      "137861/137861 [==============================] - 65s - loss: 0.2788 - acc: 0.9462    \n",
      "Epoch 982/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2802 - acc: 0.9457Epoch 00981: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2804 - acc: 0.9457    \n",
      "Epoch 983/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9443Epoch 00982: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2874 - acc: 0.9442    \n",
      "Epoch 984/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9447Epoch 00983: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2863 - acc: 0.9447    \n",
      "Epoch 985/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9451Epoch 00984: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2836 - acc: 0.9451    \n",
      "Epoch 986/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9455Epoch 00985: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2819 - acc: 0.9454    \n",
      "Epoch 987/10000\n",
      "136000/137861 [============================>.] - ETA: 1s - loss: 0.2807 - acc: 0.9458Epoch 00986: acc did not improve\n",
      "137861/137861 [==============================] - 74s - loss: 0.2806 - acc: 0.9458    \n",
      "Epoch 988/10000\n",
      "136000/137861 [============================>.] - ETA: 1s - loss: 0.2782 - acc: 0.9464Epoch 00987: acc did not improve\n",
      "137861/137861 [==============================] - 80s - loss: 0.2782 - acc: 0.9464    \n",
      "Epoch 989/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2818 - acc: 0.9459Epoch 00988: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.2818 - acc: 0.9459    \n",
      "Epoch 990/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2829 - acc: 0.9460Epoch 00989: acc did not improve\n",
      "137861/137861 [==============================] - 70s - loss: 0.2829 - acc: 0.9460    \n",
      "Epoch 991/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.9468Epoch 00990: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2798 - acc: 0.9468    \n",
      "Epoch 992/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9477Epoch 00991: acc did not improve\n",
      "137861/137861 [==============================] - 70s - loss: 0.2743 - acc: 0.9477    \n",
      "Epoch 993/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.9483Epoch 00992: acc did not improve\n",
      "137861/137861 [==============================] - 70s - loss: 0.2720 - acc: 0.9483    \n",
      "Epoch 994/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9480Epoch 00993: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.2742 - acc: 0.9480    \n",
      "Epoch 995/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9484Epoch 00994: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2713 - acc: 0.9484    \n",
      "Epoch 996/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.9492Epoch 00995: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2680 - acc: 0.9491    \n",
      "Epoch 997/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.9497Epoch 00996: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.2650 - acc: 0.9497    \n",
      "Epoch 998/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.9496Epoch 00997: acc did not improve\n",
      "137861/137861 [==============================] - 71s - loss: 0.2649 - acc: 0.9497    \n",
      "Epoch 999/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9499Epoch 00998: acc did not improve\n",
      "137861/137861 [==============================] - 70s - loss: 0.2637 - acc: 0.9499    \n",
      "Epoch 1000/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9505Epoch 00999: acc did not improve\n",
      "137861/137861 [==============================] - 70s - loss: 0.2611 - acc: 0.9505    \n",
      "Epoch 1001/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9504Epoch 01000: acc did not improve\n",
      "137861/137861 [==============================] - 71s - loss: 0.2620 - acc: 0.9504    \n",
      "Epoch 1002/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9503Epoch 01001: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.2623 - acc: 0.9503    \n",
      "Epoch 1003/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2608 - acc: 0.9508Epoch 01002: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2608 - acc: 0.9508    \n",
      "Epoch 1004/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9512Epoch 01003: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2591 - acc: 0.9512    \n",
      "Epoch 1005/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9514Epoch 01004: acc improved from 0.95128 to 0.95137, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 68s - loss: 0.2583 - acc: 0.9514    \n",
      "Epoch 1006/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2579 - acc: 0.9515Epoch 01005: acc improved from 0.95137 to 0.95145, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.2580 - acc: 0.9515    \n",
      "Epoch 1007/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9515Epoch 01006: acc improved from 0.95145 to 0.95149, saving model to weights.model_final5.hdf5\n",
      "137861/137861 [==============================] - 67s - loss: 0.2579 - acc: 0.9515    \n",
      "Epoch 1008/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.9419Epoch 01007: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3126 - acc: 0.9419    \n",
      "Epoch 1009/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.9396Epoch 01008: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3152 - acc: 0.9396    \n",
      "Epoch 1010/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.9404Epoch 01009: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3125 - acc: 0.9403    \n",
      "Epoch 1011/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.9364Epoch 01010: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3317 - acc: 0.9364    \n",
      "Epoch 1012/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3488 - acc: 0.9325Epoch 01011: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3486 - acc: 0.9326    \n",
      "Epoch 1013/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3245 - acc: 0.9380Epoch 01012: acc did not improve\n",
      "137861/137861 [==============================] - 69s - loss: 0.3243 - acc: 0.9380    \n",
      "Epoch 1014/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.9413Epoch 01013: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3077 - acc: 0.9413    \n",
      "Epoch 1015/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3002 - acc: 0.9424Epoch 01014: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3001 - acc: 0.9425    \n",
      "Epoch 1016/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.9441Epoch 01015: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2927 - acc: 0.9441    \n",
      "Epoch 1017/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9437Epoch 01016: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3010 - acc: 0.9437    \n",
      "Epoch 1018/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9450Epoch 01017: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2936 - acc: 0.9450    \n",
      "Epoch 1019/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.9455Epoch 01018: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.2893 - acc: 0.9455    \n",
      "Epoch 1020/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9468Epoch 01019: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2828 - acc: 0.9468    \n",
      "Epoch 1021/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9470Epoch 01020: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2828 - acc: 0.9470    \n",
      "Epoch 1022/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9449Epoch 01021: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2920 - acc: 0.9446    \n",
      "Epoch 1023/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.9275Epoch 01022: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3609 - acc: 0.9275    \n",
      "Epoch 1024/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.9344Epoch 01023: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3328 - acc: 0.9345    \n",
      "Epoch 1025/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.9398Epoch 01024: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3104 - acc: 0.9399    \n",
      "Epoch 1026/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9401Epoch 01025: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3125 - acc: 0.9401    \n",
      "Epoch 1027/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3194 - acc: 0.9388Epoch 01026: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3195 - acc: 0.9388    \n",
      "Epoch 1028/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.9321Epoch 01027: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3475 - acc: 0.9321    \n",
      "Epoch 1029/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.9395Epoch 01028: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3188 - acc: 0.9395    \n",
      "Epoch 1030/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3069 - acc: 0.9425Epoch 01029: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3067 - acc: 0.9426    \n",
      "Epoch 1031/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.9438Epoch 01030: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3004 - acc: 0.9438    \n",
      "Epoch 1032/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.9444Epoch 01031: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2989 - acc: 0.9444    \n",
      "Epoch 1033/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.9444Epoch 01032: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2993 - acc: 0.9444    \n",
      "Epoch 1034/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3273 - acc: 0.9394Epoch 01033: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3286 - acc: 0.9391    \n",
      "Epoch 1035/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3789 - acc: 0.9258Epoch 01034: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3785 - acc: 0.9258    \n",
      "Epoch 1036/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3518 - acc: 0.9303Epoch 01035: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3518 - acc: 0.9304    \n",
      "Epoch 1037/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.9338Epoch 01036: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3358 - acc: 0.9338    \n",
      "Epoch 1038/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.9373Epoch 01037: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3203 - acc: 0.9373    \n",
      "Epoch 1039/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.9395Epoch 01038: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3102 - acc: 0.9395    \n",
      "Epoch 1040/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9405Epoch 01039: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3054 - acc: 0.9405    \n",
      "Epoch 1041/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9396Epoch 01040: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3105 - acc: 0.9397    \n",
      "Epoch 1042/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.9415Epoch 01041: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3035 - acc: 0.9415    \n",
      "Epoch 1043/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.9235Epoch 01042: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3960 - acc: 0.9234    \n",
      "Epoch 1044/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4287 - acc: 0.9151Epoch 01043: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4291 - acc: 0.9150    \n",
      "Epoch 1045/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.9228Epoch 01044: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3905 - acc: 0.9229    \n",
      "Epoch 1046/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.9318Epoch 01045: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3460 - acc: 0.9318    \n",
      "Epoch 1047/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3313 - acc: 0.9345Epoch 01046: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3314 - acc: 0.9346    \n",
      "Epoch 1048/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3307 - acc: 0.9359Epoch 01047: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3308 - acc: 0.9359    \n",
      "Epoch 1049/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9379Epoch 01048: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3200 - acc: 0.9379    \n",
      "Epoch 1050/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3128 - acc: 0.9396Epoch 01049: acc did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137861/137861 [==============================] - 67s - loss: 0.3128 - acc: 0.9396    \n",
      "Epoch 1051/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9410Epoch 01050: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3055 - acc: 0.9410    \n",
      "Epoch 1052/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.9412Epoch 01051: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3035 - acc: 0.9412    \n",
      "Epoch 1053/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.9421Epoch 01052: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2998 - acc: 0.9421    \n",
      "Epoch 1054/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.9429Epoch 01053: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2964 - acc: 0.9429    \n",
      "Epoch 1055/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9428Epoch 01054: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2966 - acc: 0.9428    \n",
      "Epoch 1056/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.9333Epoch 01055: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3373 - acc: 0.9334    \n",
      "Epoch 1057/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3233 - acc: 0.9372Epoch 01056: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3235 - acc: 0.9372    \n",
      "Epoch 1058/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.9400Epoch 01057: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3108 - acc: 0.9400    \n",
      "Epoch 1059/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9399Epoch 01058: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3118 - acc: 0.9399    \n",
      "Epoch 1060/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.9295Epoch 01059: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3611 - acc: 0.9295    \n",
      "Epoch 1061/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.9263Epoch 01060: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3810 - acc: 0.9263    \n",
      "Epoch 1062/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.9326Epoch 01061: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3530 - acc: 0.9327    \n",
      "Epoch 1063/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.9340Epoch 01062: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3467 - acc: 0.9339    \n",
      "Epoch 1064/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.9329Epoch 01063: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3488 - acc: 0.9330    \n",
      "Epoch 1065/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.9353Epoch 01064: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3383 - acc: 0.9353    \n",
      "Epoch 1066/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.9378Epoch 01065: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3273 - acc: 0.9378    \n",
      "Epoch 1067/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.9395Epoch 01066: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3186 - acc: 0.9395    \n",
      "Epoch 1068/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.9368Epoch 01067: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3347 - acc: 0.9367    \n",
      "Epoch 1069/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.9325Epoch 01068: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3558 - acc: 0.9325    \n",
      "Epoch 1070/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.9289Epoch 01069: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3705 - acc: 0.9289    \n",
      "Epoch 1071/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.9329Epoch 01070: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3520 - acc: 0.9329    \n",
      "Epoch 1072/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.9337Epoch 01071: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3501 - acc: 0.9336    \n",
      "Epoch 1073/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3723 - acc: 0.9287Epoch 01072: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3719 - acc: 0.9288    \n",
      "Epoch 1074/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.9318Epoch 01073: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3570 - acc: 0.9317    \n",
      "Epoch 1075/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.9270Epoch 01074: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3725 - acc: 0.9270    \n",
      "Epoch 1076/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.9292Epoch 01075: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3579 - acc: 0.9292    \n",
      "Epoch 1077/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.9321Epoch 01076: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3489 - acc: 0.9321    \n",
      "Epoch 1078/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.9353Epoch 01077: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3357 - acc: 0.9353    \n",
      "Epoch 1079/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.9378Epoch 01078: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3252 - acc: 0.9378    \n",
      "Epoch 1080/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.9391Epoch 01079: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3197 - acc: 0.9390    \n",
      "Epoch 1081/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.9399Epoch 01080: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3161 - acc: 0.9399    \n",
      "Epoch 1082/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9409Epoch 01081: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3117 - acc: 0.9409    \n",
      "Epoch 1083/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3003 - acc: 0.9430Epoch 01082: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3001 - acc: 0.9430    \n",
      "Epoch 1084/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9439Epoch 01083: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.2964 - acc: 0.9439    \n",
      "Epoch 1085/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.9434Epoch 01084: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.2996 - acc: 0.9434    \n",
      "Epoch 1086/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.9336Epoch 01085: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3410 - acc: 0.9336    \n",
      "Epoch 1087/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3448 - acc: 0.9345Epoch 01086: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3451 - acc: 0.9345    \n",
      "Epoch 1088/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.9323Epoch 01087: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3599 - acc: 0.9324    \n",
      "Epoch 1089/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5006 - acc: 0.9082Epoch 01088: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.5027 - acc: 0.9077    \n",
      "Epoch 1090/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5962 - acc: 0.8900Epoch 01089: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.5949 - acc: 0.8902    \n",
      "Epoch 1091/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.9051Epoch 01090: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.5130 - acc: 0.9052    \n",
      "Epoch 1092/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4742 - acc: 0.9153Epoch 01091: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4739 - acc: 0.9153    \n",
      "Epoch 1093/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.9214Epoch 01092: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4437 - acc: 0.9214    \n",
      "Epoch 1094/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.9251Epoch 01093: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4275 - acc: 0.9250    \n",
      "Epoch 1095/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.9233Epoch 01094: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4352 - acc: 0.9233    \n",
      "Epoch 1096/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.9255Epoch 01095: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4217 - acc: 0.9255    \n",
      "Epoch 1097/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4216 - acc: 0.9262Epoch 01096: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4218 - acc: 0.9262    \n",
      "Epoch 1098/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.9301Epoch 01097: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4044 - acc: 0.9301    \n",
      "Epoch 1099/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.9322Epoch 01098: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3939 - acc: 0.9322    \n",
      "Epoch 1100/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.9343Epoch 01099: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3837 - acc: 0.9343    \n",
      "Epoch 1101/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.9331Epoch 01100: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3873 - acc: 0.9330    \n",
      "Epoch 1102/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.9351Epoch 01101: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3785 - acc: 0.9351    \n",
      "Epoch 1103/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.9349Epoch 01102: acc did not improve\n",
      "137861/137861 [==============================] - 68s - loss: 0.3825 - acc: 0.9348    \n",
      "Epoch 1104/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3794 - acc: 0.9359Epoch 01103: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3796 - acc: 0.9359    \n",
      "Epoch 1105/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.9372Epoch 01104: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3740 - acc: 0.9372    \n",
      "Epoch 1106/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.9357Epoch 01105: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3797 - acc: 0.9358    \n",
      "Epoch 1107/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.9367Epoch 01106: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3758 - acc: 0.9367    \n",
      "Epoch 1108/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.9374Epoch 01107: acc did not improve\n",
      "137861/137861 [==============================] - 66s - loss: 0.3722 - acc: 0.9374    \n",
      "Epoch 1109/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.9300Epoch 01108: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.4098 - acc: 0.9300    \n",
      "Epoch 1110/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3914 - acc: 0.9335Epoch 01109: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3915 - acc: 0.9335    \n",
      "Epoch 1111/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.9357Epoch 01110: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3816 - acc: 0.9357    \n",
      "Epoch 1112/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.9360Epoch 01111: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3807 - acc: 0.9360    \n",
      "Epoch 1113/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.9381Epoch 01112: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3695 - acc: 0.9381    \n",
      "Epoch 1114/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.9396Epoch 01113: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3625 - acc: 0.9396    \n",
      "Epoch 1115/10000\n",
      "136000/137861 [============================>.] - ETA: 0s - loss: 0.3595 - acc: 0.9402Epoch 01114: acc did not improve\n",
      "137861/137861 [==============================] - 67s - loss: 0.3593 - acc: 0.9402    \n",
      "Epoch 1116/10000\n",
      " 60000/137861 [============>.................] - ETA: 38s - loss: 0.3607 - acc: 0.9400"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    # TODO: Train neural network using model_final\n",
    "    x = pad(x,y.shape[1])\n",
    "\n",
    "    model = model_final(\n",
    "        padded_x.shape,\n",
    "        y.shape[1],\n",
    "        len(x_tk.word_index) + 1,\n",
    "        len(y_tk.word_index) + 1\n",
    "    )\n",
    "    \n",
    "    weight_path = 'weights.model_final5.hdf5'\n",
    "\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=weight_path,\n",
    "        save_best_only=True,\n",
    "        monitor='acc',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    earlystopper = EarlyStopping(\n",
    "        min_delta=0.0001,\n",
    "        patience=200,\n",
    "        #verbose=1,\n",
    "        monitor='acc'\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x,y,\n",
    "        # validation_split=0.2,\n",
    "        batch_size=4000, # Push as much data as possible per batch as our GPU can handle\n",
    "        epochs=10000,\n",
    "        callbacks=[PlotLosses(),checkpointer,earlystopper]\n",
    "    )\n",
    "\n",
    "    model.load_weights(weight_path) # Reload best weights\n",
    "\n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in y[0]]))\n",
    "\n",
    "\n",
    "final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 21, 346)           69200     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 21, 512)           2638848   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 21, 346)           1783284   \n",
      "=================================================================\n",
      "Total params: 4,491,332.0\n",
      "Trainable params: 4,491,332\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "Sample 1:\n",
      "il a vu un les camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois est pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "# This method uses the result from previous training, whose output did not persist to the output properly.\n",
    "# \n",
    "\n",
    "def new_final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    x = pad(x,y.shape[1])\n",
    "\n",
    "    model = model_final(\n",
    "        padded_x.shape,\n",
    "        y.shape[1],\n",
    "        len(x_tk.word_index) + 1,\n",
    "        len(y_tk.word_index) + 1\n",
    "    )\n",
    "    \n",
    "    # Load weights from previous training into\n",
    "    weight_path = 'weights.model_final5.hdf5'\n",
    "\n",
    "    model.load_weights(weight_path) # Reload best weights\n",
    "\n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in y[0]]))\n",
    "\n",
    "\n",
    "new_final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit your project, do the following steps:\n",
    "1. Ensure you pass all points on the [rubric](https://review.udacity.com/#!/rubrics/1004/view).\n",
    "2. Submit the following in a zip file.\n",
    "  - `helper.py`\n",
    "  - `machine_translation.ipynb`\n",
    "  - `machine_translation.html`\n",
    "    - You can export the notebook by navigating to **File -> Download as -> HTML (.html)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
